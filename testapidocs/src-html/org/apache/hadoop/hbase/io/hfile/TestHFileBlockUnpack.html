<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (17) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.apache.hadoop.hbase.io.hfile, class: TestHFileBlockUnpack">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="source-line-no">003</span><span id="line-3"> * or more contributor license agreements.  See the NOTICE file</span>
<span class="source-line-no">004</span><span id="line-4"> * distributed with this work for additional information</span>
<span class="source-line-no">005</span><span id="line-5"> * regarding copyright ownership.  The ASF licenses this file</span>
<span class="source-line-no">006</span><span id="line-6"> * to you under the Apache License, Version 2.0 (the</span>
<span class="source-line-no">007</span><span id="line-7"> * "License"); you may not use this file except in compliance</span>
<span class="source-line-no">008</span><span id="line-8"> * with the License.  You may obtain a copy of the License at</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">011</span><span id="line-11"> *</span>
<span class="source-line-no">012</span><span id="line-12"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">013</span><span id="line-13"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">014</span><span id="line-14"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="source-line-no">015</span><span id="line-15"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">016</span><span id="line-16"> * limitations under the License.</span>
<span class="source-line-no">017</span><span id="line-17"> */</span>
<span class="source-line-no">018</span><span id="line-18">package org.apache.hadoop.hbase.io.hfile;</span>
<span class="source-line-no">019</span><span id="line-19"></span>
<span class="source-line-no">020</span><span id="line-20">import static org.junit.Assert.assertEquals;</span>
<span class="source-line-no">021</span><span id="line-21">import static org.junit.Assert.assertFalse;</span>
<span class="source-line-no">022</span><span id="line-22">import static org.junit.Assert.assertTrue;</span>
<span class="source-line-no">023</span><span id="line-23"></span>
<span class="source-line-no">024</span><span id="line-24">import java.io.IOException;</span>
<span class="source-line-no">025</span><span id="line-25">import java.util.ArrayList;</span>
<span class="source-line-no">026</span><span id="line-26">import java.util.List;</span>
<span class="source-line-no">027</span><span id="line-27">import java.util.Random;</span>
<span class="source-line-no">028</span><span id="line-28">import org.apache.hadoop.conf.Configuration;</span>
<span class="source-line-no">029</span><span id="line-29">import org.apache.hadoop.fs.FSDataInputStream;</span>
<span class="source-line-no">030</span><span id="line-30">import org.apache.hadoop.fs.FSDataOutputStream;</span>
<span class="source-line-no">031</span><span id="line-31">import org.apache.hadoop.fs.FileSystem;</span>
<span class="source-line-no">032</span><span id="line-32">import org.apache.hadoop.fs.Path;</span>
<span class="source-line-no">033</span><span id="line-33">import org.apache.hadoop.hbase.HBaseClassTestRule;</span>
<span class="source-line-no">034</span><span id="line-34">import org.apache.hadoop.hbase.HBaseConfiguration;</span>
<span class="source-line-no">035</span><span id="line-35">import org.apache.hadoop.hbase.HBaseTestingUtil;</span>
<span class="source-line-no">036</span><span id="line-36">import org.apache.hadoop.hbase.HConstants;</span>
<span class="source-line-no">037</span><span id="line-37">import org.apache.hadoop.hbase.KeyValue;</span>
<span class="source-line-no">038</span><span id="line-38">import org.apache.hadoop.hbase.fs.HFileSystem;</span>
<span class="source-line-no">039</span><span id="line-39">import org.apache.hadoop.hbase.io.ByteBuffAllocator;</span>
<span class="source-line-no">040</span><span id="line-40">import org.apache.hadoop.hbase.io.FSDataInputStreamWrapper;</span>
<span class="source-line-no">041</span><span id="line-41">import org.apache.hadoop.hbase.io.compress.Compression;</span>
<span class="source-line-no">042</span><span id="line-42">import org.apache.hadoop.hbase.nio.ByteBuff;</span>
<span class="source-line-no">043</span><span id="line-43">import org.apache.hadoop.hbase.testclassification.IOTests;</span>
<span class="source-line-no">044</span><span id="line-44">import org.apache.hadoop.hbase.testclassification.MediumTests;</span>
<span class="source-line-no">045</span><span id="line-45">import org.apache.hadoop.hbase.util.Bytes;</span>
<span class="source-line-no">046</span><span id="line-46">import org.junit.Before;</span>
<span class="source-line-no">047</span><span id="line-47">import org.junit.ClassRule;</span>
<span class="source-line-no">048</span><span id="line-48">import org.junit.Rule;</span>
<span class="source-line-no">049</span><span id="line-49">import org.junit.Test;</span>
<span class="source-line-no">050</span><span id="line-50">import org.junit.experimental.categories.Category;</span>
<span class="source-line-no">051</span><span id="line-51">import org.junit.rules.TestName;</span>
<span class="source-line-no">052</span><span id="line-52"></span>
<span class="source-line-no">053</span><span id="line-53">@Category({ IOTests.class, MediumTests.class })</span>
<span class="source-line-no">054</span><span id="line-54">public class TestHFileBlockUnpack {</span>
<span class="source-line-no">055</span><span id="line-55"></span>
<span class="source-line-no">056</span><span id="line-56">  @ClassRule</span>
<span class="source-line-no">057</span><span id="line-57">  public static final HBaseClassTestRule CLASS_RULE =</span>
<span class="source-line-no">058</span><span id="line-58">    HBaseClassTestRule.forClass(TestHFileBlockUnpack.class);</span>
<span class="source-line-no">059</span><span id="line-59"></span>
<span class="source-line-no">060</span><span id="line-60">  private static final HBaseTestingUtil TEST_UTIL = new HBaseTestingUtil();</span>
<span class="source-line-no">061</span><span id="line-61"></span>
<span class="source-line-no">062</span><span id="line-62">  // repetition gives us some chance to get a good compression ratio</span>
<span class="source-line-no">063</span><span id="line-63">  private static float CHANCE_TO_REPEAT = 0.6f;</span>
<span class="source-line-no">064</span><span id="line-64"></span>
<span class="source-line-no">065</span><span id="line-65">  private static final int MIN_ALLOCATION_SIZE = 10 * 1024;</span>
<span class="source-line-no">066</span><span id="line-66"></span>
<span class="source-line-no">067</span><span id="line-67">  ByteBuffAllocator allocator;</span>
<span class="source-line-no">068</span><span id="line-68"></span>
<span class="source-line-no">069</span><span id="line-69">  @Rule</span>
<span class="source-line-no">070</span><span id="line-70">  public TestName name = new TestName();</span>
<span class="source-line-no">071</span><span id="line-71">  private FileSystem fs;</span>
<span class="source-line-no">072</span><span id="line-72"></span>
<span class="source-line-no">073</span><span id="line-73">  @Before</span>
<span class="source-line-no">074</span><span id="line-74">  public void setUp() throws Exception {</span>
<span class="source-line-no">075</span><span id="line-75">    fs = HFileSystem.get(TEST_UTIL.getConfiguration());</span>
<span class="source-line-no">076</span><span id="line-76">    Configuration conf = HBaseConfiguration.create(TEST_UTIL.getConfiguration());</span>
<span class="source-line-no">077</span><span id="line-77">    conf.setInt(ByteBuffAllocator.MIN_ALLOCATE_SIZE_KEY, MIN_ALLOCATION_SIZE);</span>
<span class="source-line-no">078</span><span id="line-78">    allocator = ByteBuffAllocator.create(conf, true);</span>
<span class="source-line-no">079</span><span id="line-79">  }</span>
<span class="source-line-no">080</span><span id="line-80"></span>
<span class="source-line-no">081</span><span id="line-81">  /**</span>
<span class="source-line-no">082</span><span id="line-82">   * It's important that if you read and unpack the same HFileBlock twice, it results in an</span>
<span class="source-line-no">083</span><span id="line-83">   * identical buffer each time. Otherwise we end up with validation failures in block cache, since</span>
<span class="source-line-no">084</span><span id="line-84">   * contents may not match if the same block is cached twice. See</span>
<span class="source-line-no">085</span><span id="line-85">   * https://issues.apache.org/jira/browse/HBASE-27053</span>
<span class="source-line-no">086</span><span id="line-86">   */</span>
<span class="source-line-no">087</span><span id="line-87">  @Test</span>
<span class="source-line-no">088</span><span id="line-88">  public void itUnpacksIdenticallyEachTime() throws IOException {</span>
<span class="source-line-no">089</span><span id="line-89">    Path path = new Path(TEST_UTIL.getDataTestDir(), name.getMethodName());</span>
<span class="source-line-no">090</span><span id="line-90">    int totalSize = createTestBlock(path);</span>
<span class="source-line-no">091</span><span id="line-91"></span>
<span class="source-line-no">092</span><span id="line-92">    // Allocate a bunch of random buffers, so we can be sure that unpack will only have "dirty"</span>
<span class="source-line-no">093</span><span id="line-93">    // buffers to choose from when allocating itself.</span>
<span class="source-line-no">094</span><span id="line-94">    Random random = new Random();</span>
<span class="source-line-no">095</span><span id="line-95">    byte[] temp = new byte[HConstants.DEFAULT_BLOCKSIZE];</span>
<span class="source-line-no">096</span><span id="line-96">    List&lt;ByteBuff&gt; buffs = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">097</span><span id="line-97">    for (int i = 0; i &lt; 10; i++) {</span>
<span class="source-line-no">098</span><span id="line-98">      ByteBuff buff = allocator.allocate(HConstants.DEFAULT_BLOCKSIZE);</span>
<span class="source-line-no">099</span><span id="line-99">      random.nextBytes(temp);</span>
<span class="source-line-no">100</span><span id="line-100">      buff.put(temp);</span>
<span class="source-line-no">101</span><span id="line-101">      buffs.add(buff);</span>
<span class="source-line-no">102</span><span id="line-102">    }</span>
<span class="source-line-no">103</span><span id="line-103"></span>
<span class="source-line-no">104</span><span id="line-104">    buffs.forEach(ByteBuff::release);</span>
<span class="source-line-no">105</span><span id="line-105"></span>
<span class="source-line-no">106</span><span id="line-106">    // read the same block twice. we should expect the underlying buffer below to</span>
<span class="source-line-no">107</span><span id="line-107">    // be identical each time</span>
<span class="source-line-no">108</span><span id="line-108">    HFileBlockWrapper blockOne = readBlock(path, totalSize);</span>
<span class="source-line-no">109</span><span id="line-109">    HFileBlockWrapper blockTwo = readBlock(path, totalSize);</span>
<span class="source-line-no">110</span><span id="line-110"></span>
<span class="source-line-no">111</span><span id="line-111">    // first check size fields</span>
<span class="source-line-no">112</span><span id="line-112">    assertEquals(blockOne.original.getOnDiskSizeWithHeader(),</span>
<span class="source-line-no">113</span><span id="line-113">      blockTwo.original.getOnDiskSizeWithHeader());</span>
<span class="source-line-no">114</span><span id="line-114">    assertEquals(blockOne.original.getUncompressedSizeWithoutHeader(),</span>
<span class="source-line-no">115</span><span id="line-115">      blockTwo.original.getUncompressedSizeWithoutHeader());</span>
<span class="source-line-no">116</span><span id="line-116"></span>
<span class="source-line-no">117</span><span id="line-117">    // next check packed buffers</span>
<span class="source-line-no">118</span><span id="line-118">    assertBuffersEqual(blockOne.original.getBufferWithoutHeader(),</span>
<span class="source-line-no">119</span><span id="line-119">      blockTwo.original.getBufferWithoutHeader(),</span>
<span class="source-line-no">120</span><span id="line-120">      blockOne.original.getOnDiskDataSizeWithHeader() - blockOne.original.headerSize());</span>
<span class="source-line-no">121</span><span id="line-121"></span>
<span class="source-line-no">122</span><span id="line-122">    // now check unpacked buffers. prior to HBASE-27053, this would fail because</span>
<span class="source-line-no">123</span><span id="line-123">    // the unpacked buffer would include extra space for checksums at the end that was not written.</span>
<span class="source-line-no">124</span><span id="line-124">    // so the checksum space would be filled with random junk when re-using pooled buffers.</span>
<span class="source-line-no">125</span><span id="line-125">    assertBuffersEqual(blockOne.unpacked.getBufferWithoutHeader(),</span>
<span class="source-line-no">126</span><span id="line-126">      blockTwo.unpacked.getBufferWithoutHeader(),</span>
<span class="source-line-no">127</span><span id="line-127">      blockOne.original.getUncompressedSizeWithoutHeader());</span>
<span class="source-line-no">128</span><span id="line-128">  }</span>
<span class="source-line-no">129</span><span id="line-129"></span>
<span class="source-line-no">130</span><span id="line-130">  private void assertBuffersEqual(ByteBuff bufferOne, ByteBuff bufferTwo, int expectedSize) {</span>
<span class="source-line-no">131</span><span id="line-131">    assertEquals(expectedSize, bufferOne.limit());</span>
<span class="source-line-no">132</span><span id="line-132">    assertEquals(expectedSize, bufferTwo.limit());</span>
<span class="source-line-no">133</span><span id="line-133">    assertEquals(0,</span>
<span class="source-line-no">134</span><span id="line-134">      ByteBuff.compareTo(bufferOne, 0, bufferOne.limit(), bufferTwo, 0, bufferTwo.limit()));</span>
<span class="source-line-no">135</span><span id="line-135">  }</span>
<span class="source-line-no">136</span><span id="line-136"></span>
<span class="source-line-no">137</span><span id="line-137">  /**</span>
<span class="source-line-no">138</span><span id="line-138">   * If the block on disk size is less than {@link ByteBuffAllocator}'s min allocation size, that</span>
<span class="source-line-no">139</span><span id="line-139">   * block will be allocated to heap regardless of desire for off-heap. After de-compressing the</span>
<span class="source-line-no">140</span><span id="line-140">   * block, the new size may now exceed the min allocation size. This test ensures that those</span>
<span class="source-line-no">141</span><span id="line-141">   * de-compressed blocks, which will be allocated off-heap, are properly marked as</span>
<span class="source-line-no">142</span><span id="line-142">   * {@link HFileBlock#isSharedMem()} == true See https://issues.apache.org/jira/browse/HBASE-27170</span>
<span class="source-line-no">143</span><span id="line-143">   */</span>
<span class="source-line-no">144</span><span id="line-144">  @Test</span>
<span class="source-line-no">145</span><span id="line-145">  public void itUsesSharedMemoryIfUnpackedBlockExceedsMinAllocationSize() throws IOException {</span>
<span class="source-line-no">146</span><span id="line-146">    Path path = new Path(TEST_UTIL.getDataTestDir(), name.getMethodName());</span>
<span class="source-line-no">147</span><span id="line-147">    int totalSize = createTestBlock(path);</span>
<span class="source-line-no">148</span><span id="line-148">    HFileBlockWrapper blockFromHFile = readBlock(path, totalSize);</span>
<span class="source-line-no">149</span><span id="line-149"></span>
<span class="source-line-no">150</span><span id="line-150">    assertFalse("expected hfile block to NOT be unpacked", blockFromHFile.original.isUnpacked());</span>
<span class="source-line-no">151</span><span id="line-151">    assertFalse("expected hfile block to NOT use shared memory",</span>
<span class="source-line-no">152</span><span id="line-152">      blockFromHFile.original.isSharedMem());</span>
<span class="source-line-no">153</span><span id="line-153"></span>
<span class="source-line-no">154</span><span id="line-154">    assertTrue(</span>
<span class="source-line-no">155</span><span id="line-155">      "expected generated block size " + blockFromHFile.original.getOnDiskSizeWithHeader()</span>
<span class="source-line-no">156</span><span id="line-156">        + " to be less than " + MIN_ALLOCATION_SIZE,</span>
<span class="source-line-no">157</span><span id="line-157">      blockFromHFile.original.getOnDiskSizeWithHeader() &lt; MIN_ALLOCATION_SIZE);</span>
<span class="source-line-no">158</span><span id="line-158">    assertTrue(</span>
<span class="source-line-no">159</span><span id="line-159">      "expected generated block uncompressed size "</span>
<span class="source-line-no">160</span><span id="line-160">        + blockFromHFile.original.getUncompressedSizeWithoutHeader() + " to be more than "</span>
<span class="source-line-no">161</span><span id="line-161">        + MIN_ALLOCATION_SIZE,</span>
<span class="source-line-no">162</span><span id="line-162">      blockFromHFile.original.getUncompressedSizeWithoutHeader() &gt; MIN_ALLOCATION_SIZE);</span>
<span class="source-line-no">163</span><span id="line-163"></span>
<span class="source-line-no">164</span><span id="line-164">    assertTrue("expected unpacked block to be unpacked", blockFromHFile.unpacked.isUnpacked());</span>
<span class="source-line-no">165</span><span id="line-165">    assertTrue("expected unpacked block to use shared memory",</span>
<span class="source-line-no">166</span><span id="line-166">      blockFromHFile.unpacked.isSharedMem());</span>
<span class="source-line-no">167</span><span id="line-167">  }</span>
<span class="source-line-no">168</span><span id="line-168"></span>
<span class="source-line-no">169</span><span id="line-169">  private final static class HFileBlockWrapper {</span>
<span class="source-line-no">170</span><span id="line-170">    private final HFileBlock original;</span>
<span class="source-line-no">171</span><span id="line-171">    private final HFileBlock unpacked;</span>
<span class="source-line-no">172</span><span id="line-172"></span>
<span class="source-line-no">173</span><span id="line-173">    private HFileBlockWrapper(HFileBlock original, HFileBlock unpacked) {</span>
<span class="source-line-no">174</span><span id="line-174">      this.original = original;</span>
<span class="source-line-no">175</span><span id="line-175">      this.unpacked = unpacked;</span>
<span class="source-line-no">176</span><span id="line-176">    }</span>
<span class="source-line-no">177</span><span id="line-177">  }</span>
<span class="source-line-no">178</span><span id="line-178"></span>
<span class="source-line-no">179</span><span id="line-179">  private HFileBlockWrapper readBlock(Path path, int totalSize) throws IOException {</span>
<span class="source-line-no">180</span><span id="line-180">    try (FSDataInputStream is = fs.open(path)) {</span>
<span class="source-line-no">181</span><span id="line-181">      HFileContext meta =</span>
<span class="source-line-no">182</span><span id="line-182">        new HFileContextBuilder().withHBaseCheckSum(true).withCompression(Compression.Algorithm.GZ)</span>
<span class="source-line-no">183</span><span id="line-183">          .withIncludesMvcc(false).withIncludesTags(false).build();</span>
<span class="source-line-no">184</span><span id="line-184">      ReaderContext context =</span>
<span class="source-line-no">185</span><span id="line-185">        new ReaderContextBuilder().withInputStreamWrapper(new FSDataInputStreamWrapper(is))</span>
<span class="source-line-no">186</span><span id="line-186">          .withFileSize(totalSize).withFilePath(path).withFileSystem(fs).build();</span>
<span class="source-line-no">187</span><span id="line-187">      HFileBlock.FSReaderImpl hbr =</span>
<span class="source-line-no">188</span><span id="line-188">        new HFileBlock.FSReaderImpl(context, meta, allocator, TEST_UTIL.getConfiguration());</span>
<span class="source-line-no">189</span><span id="line-189">      hbr.setDataBlockEncoder(NoOpDataBlockEncoder.INSTANCE, TEST_UTIL.getConfiguration());</span>
<span class="source-line-no">190</span><span id="line-190">      hbr.setIncludesMemStoreTS(false);</span>
<span class="source-line-no">191</span><span id="line-191">      HFileBlock blockFromHFile = hbr.readBlockData(0, -1, false, false, false);</span>
<span class="source-line-no">192</span><span id="line-192">      blockFromHFile.sanityCheck();</span>
<span class="source-line-no">193</span><span id="line-193">      return new HFileBlockWrapper(blockFromHFile, blockFromHFile.unpack(meta, hbr));</span>
<span class="source-line-no">194</span><span id="line-194">    }</span>
<span class="source-line-no">195</span><span id="line-195">  }</span>
<span class="source-line-no">196</span><span id="line-196"></span>
<span class="source-line-no">197</span><span id="line-197">  private int createTestBlock(Path path) throws IOException {</span>
<span class="source-line-no">198</span><span id="line-198">    HFileContext meta =</span>
<span class="source-line-no">199</span><span id="line-199">      new HFileContextBuilder().withCompression(Compression.Algorithm.GZ).withIncludesMvcc(false)</span>
<span class="source-line-no">200</span><span id="line-200">        .withIncludesTags(false).withBytesPerCheckSum(HFile.DEFAULT_BYTES_PER_CHECKSUM).build();</span>
<span class="source-line-no">201</span><span id="line-201"></span>
<span class="source-line-no">202</span><span id="line-202">    int totalSize;</span>
<span class="source-line-no">203</span><span id="line-203">    try (FSDataOutputStream os = fs.create(path)) {</span>
<span class="source-line-no">204</span><span id="line-204">      HFileBlock.Writer hbw =</span>
<span class="source-line-no">205</span><span id="line-205">        new HFileBlock.Writer(TEST_UTIL.getConfiguration(), NoOpDataBlockEncoder.INSTANCE, meta);</span>
<span class="source-line-no">206</span><span id="line-206">      hbw.startWriting(BlockType.DATA);</span>
<span class="source-line-no">207</span><span id="line-207">      writeTestKeyValues(hbw, MIN_ALLOCATION_SIZE - 1);</span>
<span class="source-line-no">208</span><span id="line-208">      hbw.writeHeaderAndData(os);</span>
<span class="source-line-no">209</span><span id="line-209">      totalSize = hbw.getOnDiskSizeWithHeader();</span>
<span class="source-line-no">210</span><span id="line-210">      assertTrue(</span>
<span class="source-line-no">211</span><span id="line-211">        "expected generated block size " + totalSize + " to be less than " + MIN_ALLOCATION_SIZE,</span>
<span class="source-line-no">212</span><span id="line-212">        totalSize &lt; MIN_ALLOCATION_SIZE);</span>
<span class="source-line-no">213</span><span id="line-213">    }</span>
<span class="source-line-no">214</span><span id="line-214">    return totalSize;</span>
<span class="source-line-no">215</span><span id="line-215">  }</span>
<span class="source-line-no">216</span><span id="line-216"></span>
<span class="source-line-no">217</span><span id="line-217">  static int writeTestKeyValues(HFileBlock.Writer hbw, int desiredSize) throws IOException {</span>
<span class="source-line-no">218</span><span id="line-218">    Random random = new Random(42);</span>
<span class="source-line-no">219</span><span id="line-219"></span>
<span class="source-line-no">220</span><span id="line-220">    byte[] family = new byte[] { 1 };</span>
<span class="source-line-no">221</span><span id="line-221">    int rowKey = 0;</span>
<span class="source-line-no">222</span><span id="line-222">    int qualifier = 0;</span>
<span class="source-line-no">223</span><span id="line-223">    int value = 0;</span>
<span class="source-line-no">224</span><span id="line-224">    long timestamp = 0;</span>
<span class="source-line-no">225</span><span id="line-225"></span>
<span class="source-line-no">226</span><span id="line-226">    int totalSize = 0;</span>
<span class="source-line-no">227</span><span id="line-227"></span>
<span class="source-line-no">228</span><span id="line-228">    // go until just up to the limit. compression should bring the total on-disk size under</span>
<span class="source-line-no">229</span><span id="line-229">    while (totalSize &lt; desiredSize) {</span>
<span class="source-line-no">230</span><span id="line-230">      rowKey = maybeIncrement(random, rowKey);</span>
<span class="source-line-no">231</span><span id="line-231">      qualifier = maybeIncrement(random, qualifier);</span>
<span class="source-line-no">232</span><span id="line-232">      value = maybeIncrement(random, value);</span>
<span class="source-line-no">233</span><span id="line-233">      timestamp = maybeIncrement(random, (int) timestamp);</span>
<span class="source-line-no">234</span><span id="line-234"></span>
<span class="source-line-no">235</span><span id="line-235">      KeyValue keyValue = new KeyValue(Bytes.toBytes(rowKey), family, Bytes.toBytes(qualifier),</span>
<span class="source-line-no">236</span><span id="line-236">        timestamp, Bytes.toBytes(value));</span>
<span class="source-line-no">237</span><span id="line-237">      hbw.write(keyValue);</span>
<span class="source-line-no">238</span><span id="line-238">      totalSize += keyValue.getLength();</span>
<span class="source-line-no">239</span><span id="line-239">    }</span>
<span class="source-line-no">240</span><span id="line-240"></span>
<span class="source-line-no">241</span><span id="line-241">    return totalSize;</span>
<span class="source-line-no">242</span><span id="line-242">  }</span>
<span class="source-line-no">243</span><span id="line-243"></span>
<span class="source-line-no">244</span><span id="line-244">  private static int maybeIncrement(Random random, int value) {</span>
<span class="source-line-no">245</span><span id="line-245">    if (random.nextFloat() &lt; CHANCE_TO_REPEAT) {</span>
<span class="source-line-no">246</span><span id="line-246">      return value;</span>
<span class="source-line-no">247</span><span id="line-247">    }</span>
<span class="source-line-no">248</span><span id="line-248">    return value + 1;</span>
<span class="source-line-no">249</span><span id="line-249">  }</span>
<span class="source-line-no">250</span><span id="line-250"></span>
<span class="source-line-no">251</span><span id="line-251">}</span>




























































</pre>
</div>
</main>
</body>
</html>
