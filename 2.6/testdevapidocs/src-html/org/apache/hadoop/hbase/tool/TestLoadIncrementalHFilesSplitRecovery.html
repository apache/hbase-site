<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (17) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.apache.hadoop.hbase.tool, class: TestLoadIncrementalHFilesSplitRecovery">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="source-line-no">003</span><span id="line-3"> * or more contributor license agreements.  See the NOTICE file</span>
<span class="source-line-no">004</span><span id="line-4"> * distributed with this work for additional information</span>
<span class="source-line-no">005</span><span id="line-5"> * regarding copyright ownership.  The ASF licenses this file</span>
<span class="source-line-no">006</span><span id="line-6"> * to you under the Apache License, Version 2.0 (the</span>
<span class="source-line-no">007</span><span id="line-7"> * "License"); you may not use this file except in compliance</span>
<span class="source-line-no">008</span><span id="line-8"> * with the License.  You may obtain a copy of the License at</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">011</span><span id="line-11"> *</span>
<span class="source-line-no">012</span><span id="line-12"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">013</span><span id="line-13"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">014</span><span id="line-14"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="source-line-no">015</span><span id="line-15"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">016</span><span id="line-16"> * limitations under the License.</span>
<span class="source-line-no">017</span><span id="line-17"> */</span>
<span class="source-line-no">018</span><span id="line-18">package org.apache.hadoop.hbase.tool;</span>
<span class="source-line-no">019</span><span id="line-19"></span>
<span class="source-line-no">020</span><span id="line-20">import static org.junit.Assert.assertArrayEquals;</span>
<span class="source-line-no">021</span><span id="line-21">import static org.junit.Assert.assertEquals;</span>
<span class="source-line-no">022</span><span id="line-22">import static org.junit.Assert.assertNotNull;</span>
<span class="source-line-no">023</span><span id="line-23">import static org.junit.Assert.assertNull;</span>
<span class="source-line-no">024</span><span id="line-24">import static org.junit.Assert.assertTrue;</span>
<span class="source-line-no">025</span><span id="line-25">import static org.junit.Assert.fail;</span>
<span class="source-line-no">026</span><span id="line-26"></span>
<span class="source-line-no">027</span><span id="line-27">import java.io.IOException;</span>
<span class="source-line-no">028</span><span id="line-28">import java.nio.ByteBuffer;</span>
<span class="source-line-no">029</span><span id="line-29">import java.util.Collection;</span>
<span class="source-line-no">030</span><span id="line-30">import java.util.Collections;</span>
<span class="source-line-no">031</span><span id="line-31">import java.util.Deque;</span>
<span class="source-line-no">032</span><span id="line-32">import java.util.List;</span>
<span class="source-line-no">033</span><span id="line-33">import java.util.Map;</span>
<span class="source-line-no">034</span><span id="line-34">import java.util.concurrent.ExecutorService;</span>
<span class="source-line-no">035</span><span id="line-35">import java.util.concurrent.atomic.AtomicInteger;</span>
<span class="source-line-no">036</span><span id="line-36">import java.util.stream.IntStream;</span>
<span class="source-line-no">037</span><span id="line-37">import org.apache.hadoop.conf.Configuration;</span>
<span class="source-line-no">038</span><span id="line-38">import org.apache.hadoop.fs.FileSystem;</span>
<span class="source-line-no">039</span><span id="line-39">import org.apache.hadoop.fs.Path;</span>
<span class="source-line-no">040</span><span id="line-40">import org.apache.hadoop.hbase.HBaseClassTestRule;</span>
<span class="source-line-no">041</span><span id="line-41">import org.apache.hadoop.hbase.HBaseTestingUtility;</span>
<span class="source-line-no">042</span><span id="line-42">import org.apache.hadoop.hbase.HConstants;</span>
<span class="source-line-no">043</span><span id="line-43">import org.apache.hadoop.hbase.HRegionLocation;</span>
<span class="source-line-no">044</span><span id="line-44">import org.apache.hadoop.hbase.MetaTableAccessor;</span>
<span class="source-line-no">045</span><span id="line-45">import org.apache.hadoop.hbase.ServerName;</span>
<span class="source-line-no">046</span><span id="line-46">import org.apache.hadoop.hbase.TableExistsException;</span>
<span class="source-line-no">047</span><span id="line-47">import org.apache.hadoop.hbase.TableName;</span>
<span class="source-line-no">048</span><span id="line-48">import org.apache.hadoop.hbase.client.Admin;</span>
<span class="source-line-no">049</span><span id="line-49">import org.apache.hadoop.hbase.client.ClientServiceCallable;</span>
<span class="source-line-no">050</span><span id="line-50">import org.apache.hadoop.hbase.client.ClusterConnection;</span>
<span class="source-line-no">051</span><span id="line-51">import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;</span>
<span class="source-line-no">052</span><span id="line-52">import org.apache.hadoop.hbase.client.Connection;</span>
<span class="source-line-no">053</span><span id="line-53">import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span class="source-line-no">054</span><span id="line-54">import org.apache.hadoop.hbase.client.RegionInfo;</span>
<span class="source-line-no">055</span><span id="line-55">import org.apache.hadoop.hbase.client.RegionInfoBuilder;</span>
<span class="source-line-no">056</span><span id="line-56">import org.apache.hadoop.hbase.client.RegionLocator;</span>
<span class="source-line-no">057</span><span id="line-57">import org.apache.hadoop.hbase.client.Result;</span>
<span class="source-line-no">058</span><span id="line-58">import org.apache.hadoop.hbase.client.ResultScanner;</span>
<span class="source-line-no">059</span><span id="line-59">import org.apache.hadoop.hbase.client.Scan;</span>
<span class="source-line-no">060</span><span id="line-60">import org.apache.hadoop.hbase.client.Table;</span>
<span class="source-line-no">061</span><span id="line-61">import org.apache.hadoop.hbase.client.TableDescriptor;</span>
<span class="source-line-no">062</span><span id="line-62">import org.apache.hadoop.hbase.client.TableDescriptorBuilder;</span>
<span class="source-line-no">063</span><span id="line-63">import org.apache.hadoop.hbase.coprocessor.CoprocessorHost;</span>
<span class="source-line-no">064</span><span id="line-64">import org.apache.hadoop.hbase.ipc.RpcControllerFactory;</span>
<span class="source-line-no">065</span><span id="line-65">import org.apache.hadoop.hbase.log.HBaseMarkers;</span>
<span class="source-line-no">066</span><span id="line-66">import org.apache.hadoop.hbase.regionserver.HRegionServer;</span>
<span class="source-line-no">067</span><span id="line-67">import org.apache.hadoop.hbase.regionserver.TestHRegionServerBulkLoad;</span>
<span class="source-line-no">068</span><span id="line-68">import org.apache.hadoop.hbase.testclassification.LargeTests;</span>
<span class="source-line-no">069</span><span id="line-69">import org.apache.hadoop.hbase.testclassification.MiscTests;</span>
<span class="source-line-no">070</span><span id="line-70">import org.apache.hadoop.hbase.util.Bytes;</span>
<span class="source-line-no">071</span><span id="line-71">import org.apache.hadoop.hbase.util.CommonFSUtils;</span>
<span class="source-line-no">072</span><span id="line-72">import org.apache.hadoop.hbase.util.Pair;</span>
<span class="source-line-no">073</span><span id="line-73">import org.junit.AfterClass;</span>
<span class="source-line-no">074</span><span id="line-74">import org.junit.BeforeClass;</span>
<span class="source-line-no">075</span><span id="line-75">import org.junit.ClassRule;</span>
<span class="source-line-no">076</span><span id="line-76">import org.junit.Rule;</span>
<span class="source-line-no">077</span><span id="line-77">import org.junit.Test;</span>
<span class="source-line-no">078</span><span id="line-78">import org.junit.experimental.categories.Category;</span>
<span class="source-line-no">079</span><span id="line-79">import org.junit.rules.TestName;</span>
<span class="source-line-no">080</span><span id="line-80">import org.mockito.Mockito;</span>
<span class="source-line-no">081</span><span id="line-81">import org.slf4j.Logger;</span>
<span class="source-line-no">082</span><span id="line-82">import org.slf4j.LoggerFactory;</span>
<span class="source-line-no">083</span><span id="line-83"></span>
<span class="source-line-no">084</span><span id="line-84">import org.apache.hbase.thirdparty.com.google.common.collect.Multimap;</span>
<span class="source-line-no">085</span><span id="line-85">import org.apache.hbase.thirdparty.com.google.protobuf.RpcController;</span>
<span class="source-line-no">086</span><span id="line-86">import org.apache.hbase.thirdparty.com.google.protobuf.ServiceException;</span>
<span class="source-line-no">087</span><span id="line-87"></span>
<span class="source-line-no">088</span><span id="line-88">import org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil;</span>
<span class="source-line-no">089</span><span id="line-89">import org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos;</span>
<span class="source-line-no">090</span><span id="line-90">import org.apache.hadoop.hbase.shaded.protobuf.generated.ClientProtos.BulkLoadHFileRequest;</span>
<span class="source-line-no">091</span><span id="line-91"></span>
<span class="source-line-no">092</span><span id="line-92">/**</span>
<span class="source-line-no">093</span><span id="line-93"> * Test cases for the atomic load error handling of the bulk load functionality.</span>
<span class="source-line-no">094</span><span id="line-94"> */</span>
<span class="source-line-no">095</span><span id="line-95">@Category({ MiscTests.class, LargeTests.class })</span>
<span class="source-line-no">096</span><span id="line-96">public class TestLoadIncrementalHFilesSplitRecovery {</span>
<span class="source-line-no">097</span><span id="line-97"></span>
<span class="source-line-no">098</span><span id="line-98">  @ClassRule</span>
<span class="source-line-no">099</span><span id="line-99">  public static final HBaseClassTestRule CLASS_RULE =</span>
<span class="source-line-no">100</span><span id="line-100">    HBaseClassTestRule.forClass(TestLoadIncrementalHFilesSplitRecovery.class);</span>
<span class="source-line-no">101</span><span id="line-101"></span>
<span class="source-line-no">102</span><span id="line-102">  private static final Logger LOG = LoggerFactory.getLogger(TestHRegionServerBulkLoad.class);</span>
<span class="source-line-no">103</span><span id="line-103"></span>
<span class="source-line-no">104</span><span id="line-104">  static HBaseTestingUtility util;</span>
<span class="source-line-no">105</span><span id="line-105">  // used by secure subclass</span>
<span class="source-line-no">106</span><span id="line-106">  static boolean useSecure = false;</span>
<span class="source-line-no">107</span><span id="line-107"></span>
<span class="source-line-no">108</span><span id="line-108">  final static int NUM_CFS = 10;</span>
<span class="source-line-no">109</span><span id="line-109">  final static byte[] QUAL = Bytes.toBytes("qual");</span>
<span class="source-line-no">110</span><span id="line-110">  final static int ROWCOUNT = 100;</span>
<span class="source-line-no">111</span><span id="line-111"></span>
<span class="source-line-no">112</span><span id="line-112">  private final static byte[][] families = new byte[NUM_CFS][];</span>
<span class="source-line-no">113</span><span id="line-113"></span>
<span class="source-line-no">114</span><span id="line-114">  @Rule</span>
<span class="source-line-no">115</span><span id="line-115">  public TestName name = new TestName();</span>
<span class="source-line-no">116</span><span id="line-116"></span>
<span class="source-line-no">117</span><span id="line-117">  static {</span>
<span class="source-line-no">118</span><span id="line-118">    for (int i = 0; i &lt; NUM_CFS; i++) {</span>
<span class="source-line-no">119</span><span id="line-119">      families[i] = Bytes.toBytes(family(i));</span>
<span class="source-line-no">120</span><span id="line-120">    }</span>
<span class="source-line-no">121</span><span id="line-121">  }</span>
<span class="source-line-no">122</span><span id="line-122"></span>
<span class="source-line-no">123</span><span id="line-123">  static byte[] rowkey(int i) {</span>
<span class="source-line-no">124</span><span id="line-124">    return Bytes.toBytes(String.format("row_%08d", i));</span>
<span class="source-line-no">125</span><span id="line-125">  }</span>
<span class="source-line-no">126</span><span id="line-126"></span>
<span class="source-line-no">127</span><span id="line-127">  static String family(int i) {</span>
<span class="source-line-no">128</span><span id="line-128">    return String.format("family_%04d", i);</span>
<span class="source-line-no">129</span><span id="line-129">  }</span>
<span class="source-line-no">130</span><span id="line-130"></span>
<span class="source-line-no">131</span><span id="line-131">  static byte[] value(int i) {</span>
<span class="source-line-no">132</span><span id="line-132">    return Bytes.toBytes(String.format("%010d", i));</span>
<span class="source-line-no">133</span><span id="line-133">  }</span>
<span class="source-line-no">134</span><span id="line-134"></span>
<span class="source-line-no">135</span><span id="line-135">  public static void buildHFiles(FileSystem fs, Path dir, int value) throws IOException {</span>
<span class="source-line-no">136</span><span id="line-136">    byte[] val = value(value);</span>
<span class="source-line-no">137</span><span id="line-137">    for (int i = 0; i &lt; NUM_CFS; i++) {</span>
<span class="source-line-no">138</span><span id="line-138">      Path testIn = new Path(dir, family(i));</span>
<span class="source-line-no">139</span><span id="line-139"></span>
<span class="source-line-no">140</span><span id="line-140">      TestHRegionServerBulkLoad.createHFile(fs, new Path(testIn, "hfile_" + i),</span>
<span class="source-line-no">141</span><span id="line-141">        Bytes.toBytes(family(i)), QUAL, val, ROWCOUNT);</span>
<span class="source-line-no">142</span><span id="line-142">    }</span>
<span class="source-line-no">143</span><span id="line-143">  }</span>
<span class="source-line-no">144</span><span id="line-144"></span>
<span class="source-line-no">145</span><span id="line-145">  private TableDescriptor createTableDesc(TableName name, int cfs) {</span>
<span class="source-line-no">146</span><span id="line-146">    TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(name);</span>
<span class="source-line-no">147</span><span id="line-147">    IntStream.range(0, cfs).mapToObj(i -&gt; ColumnFamilyDescriptorBuilder.of(family(i)))</span>
<span class="source-line-no">148</span><span id="line-148">      .forEachOrdered(builder::setColumnFamily);</span>
<span class="source-line-no">149</span><span id="line-149">    return builder.build();</span>
<span class="source-line-no">150</span><span id="line-150">  }</span>
<span class="source-line-no">151</span><span id="line-151"></span>
<span class="source-line-no">152</span><span id="line-152">  /**</span>
<span class="source-line-no">153</span><span id="line-153">   * Creates a table with given table name and specified number of column families if the table does</span>
<span class="source-line-no">154</span><span id="line-154">   * not already exist.</span>
<span class="source-line-no">155</span><span id="line-155">   */</span>
<span class="source-line-no">156</span><span id="line-156">  private void setupTable(final Connection connection, TableName table, int cfs)</span>
<span class="source-line-no">157</span><span id="line-157">    throws IOException {</span>
<span class="source-line-no">158</span><span id="line-158">    try {</span>
<span class="source-line-no">159</span><span id="line-159">      LOG.info("Creating table " + table);</span>
<span class="source-line-no">160</span><span id="line-160">      try (Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">161</span><span id="line-161">        admin.createTable(createTableDesc(table, cfs));</span>
<span class="source-line-no">162</span><span id="line-162">      }</span>
<span class="source-line-no">163</span><span id="line-163">    } catch (TableExistsException tee) {</span>
<span class="source-line-no">164</span><span id="line-164">      LOG.info("Table " + table + " already exists");</span>
<span class="source-line-no">165</span><span id="line-165">    }</span>
<span class="source-line-no">166</span><span id="line-166">  }</span>
<span class="source-line-no">167</span><span id="line-167"></span>
<span class="source-line-no">168</span><span id="line-168">  /**</span>
<span class="source-line-no">169</span><span id="line-169">   * Creates a table with given table name,specified number of column families&lt;br&gt;</span>
<span class="source-line-no">170</span><span id="line-170">   * and splitkeys if the table does not already exist.</span>
<span class="source-line-no">171</span><span id="line-171">   */</span>
<span class="source-line-no">172</span><span id="line-172">  private void setupTableWithSplitkeys(TableName table, int cfs, byte[][] SPLIT_KEYS)</span>
<span class="source-line-no">173</span><span id="line-173">    throws IOException {</span>
<span class="source-line-no">174</span><span id="line-174">    try {</span>
<span class="source-line-no">175</span><span id="line-175">      LOG.info("Creating table " + table);</span>
<span class="source-line-no">176</span><span id="line-176">      util.createTable(createTableDesc(table, cfs), SPLIT_KEYS);</span>
<span class="source-line-no">177</span><span id="line-177">    } catch (TableExistsException tee) {</span>
<span class="source-line-no">178</span><span id="line-178">      LOG.info("Table " + table + " already exists");</span>
<span class="source-line-no">179</span><span id="line-179">    }</span>
<span class="source-line-no">180</span><span id="line-180">  }</span>
<span class="source-line-no">181</span><span id="line-181"></span>
<span class="source-line-no">182</span><span id="line-182">  private Path buildBulkFiles(TableName table, int value) throws Exception {</span>
<span class="source-line-no">183</span><span id="line-183">    Path dir = util.getDataTestDirOnTestFS(table.getNameAsString());</span>
<span class="source-line-no">184</span><span id="line-184">    Path bulk1 = new Path(dir, table.getNameAsString() + value);</span>
<span class="source-line-no">185</span><span id="line-185">    FileSystem fs = util.getTestFileSystem();</span>
<span class="source-line-no">186</span><span id="line-186">    buildHFiles(fs, bulk1, value);</span>
<span class="source-line-no">187</span><span id="line-187">    return bulk1;</span>
<span class="source-line-no">188</span><span id="line-188">  }</span>
<span class="source-line-no">189</span><span id="line-189"></span>
<span class="source-line-no">190</span><span id="line-190">  /**</span>
<span class="source-line-no">191</span><span id="line-191">   * Populate table with known values.</span>
<span class="source-line-no">192</span><span id="line-192">   */</span>
<span class="source-line-no">193</span><span id="line-193">  private void populateTable(final Connection connection, TableName table, int value)</span>
<span class="source-line-no">194</span><span id="line-194">    throws Exception {</span>
<span class="source-line-no">195</span><span id="line-195">    // create HFiles for different column families</span>
<span class="source-line-no">196</span><span id="line-196">    LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration());</span>
<span class="source-line-no">197</span><span id="line-197">    Path bulk1 = buildBulkFiles(table, value);</span>
<span class="source-line-no">198</span><span id="line-198">    try (Table t = connection.getTable(table);</span>
<span class="source-line-no">199</span><span id="line-199">      RegionLocator locator = connection.getRegionLocator(table);</span>
<span class="source-line-no">200</span><span id="line-200">      Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">201</span><span id="line-201">      lih.doBulkLoad(bulk1, admin, t, locator);</span>
<span class="source-line-no">202</span><span id="line-202">    }</span>
<span class="source-line-no">203</span><span id="line-203">  }</span>
<span class="source-line-no">204</span><span id="line-204"></span>
<span class="source-line-no">205</span><span id="line-205">  /**</span>
<span class="source-line-no">206</span><span id="line-206">   * Split the known table in half. (this is hard coded for this test suite)</span>
<span class="source-line-no">207</span><span id="line-207">   */</span>
<span class="source-line-no">208</span><span id="line-208">  private void forceSplit(TableName table) {</span>
<span class="source-line-no">209</span><span id="line-209">    try {</span>
<span class="source-line-no">210</span><span id="line-210">      // need to call regions server to by synchronous but isn't visible.</span>
<span class="source-line-no">211</span><span id="line-211">      HRegionServer hrs = util.getRSForFirstRegionInTable(table);</span>
<span class="source-line-no">212</span><span id="line-212"></span>
<span class="source-line-no">213</span><span id="line-213">      for (RegionInfo hri : ProtobufUtil.getOnlineRegions(hrs.getRSRpcServices())) {</span>
<span class="source-line-no">214</span><span id="line-214">        if (hri.getTable().equals(table)) {</span>
<span class="source-line-no">215</span><span id="line-215">          util.getAdmin().splitRegionAsync(hri.getRegionName(), rowkey(ROWCOUNT / 2));</span>
<span class="source-line-no">216</span><span id="line-216">          // ProtobufUtil.split(null, hrs.getRSRpcServices(), hri, rowkey(ROWCOUNT / 2));</span>
<span class="source-line-no">217</span><span id="line-217">        }</span>
<span class="source-line-no">218</span><span id="line-218">      }</span>
<span class="source-line-no">219</span><span id="line-219"></span>
<span class="source-line-no">220</span><span id="line-220">      // verify that split completed.</span>
<span class="source-line-no">221</span><span id="line-221">      int regions;</span>
<span class="source-line-no">222</span><span id="line-222">      do {</span>
<span class="source-line-no">223</span><span id="line-223">        regions = 0;</span>
<span class="source-line-no">224</span><span id="line-224">        for (RegionInfo hri : ProtobufUtil.getOnlineRegions(hrs.getRSRpcServices())) {</span>
<span class="source-line-no">225</span><span id="line-225">          if (hri.getTable().equals(table)) {</span>
<span class="source-line-no">226</span><span id="line-226">            regions++;</span>
<span class="source-line-no">227</span><span id="line-227">          }</span>
<span class="source-line-no">228</span><span id="line-228">        }</span>
<span class="source-line-no">229</span><span id="line-229">        if (regions != 2) {</span>
<span class="source-line-no">230</span><span id="line-230">          LOG.info("Taking some time to complete split...");</span>
<span class="source-line-no">231</span><span id="line-231">          Thread.sleep(250);</span>
<span class="source-line-no">232</span><span id="line-232">        }</span>
<span class="source-line-no">233</span><span id="line-233">      } while (regions != 2);</span>
<span class="source-line-no">234</span><span id="line-234">    } catch (IOException e) {</span>
<span class="source-line-no">235</span><span id="line-235">      e.printStackTrace();</span>
<span class="source-line-no">236</span><span id="line-236">    } catch (InterruptedException e) {</span>
<span class="source-line-no">237</span><span id="line-237">      e.printStackTrace();</span>
<span class="source-line-no">238</span><span id="line-238">    }</span>
<span class="source-line-no">239</span><span id="line-239">  }</span>
<span class="source-line-no">240</span><span id="line-240"></span>
<span class="source-line-no">241</span><span id="line-241">  @BeforeClass</span>
<span class="source-line-no">242</span><span id="line-242">  public static void setupCluster() throws Exception {</span>
<span class="source-line-no">243</span><span id="line-243">    util = new HBaseTestingUtility();</span>
<span class="source-line-no">244</span><span id="line-244">    util.getConfiguration().set(CoprocessorHost.REGION_COPROCESSOR_CONF_KEY, "");</span>
<span class="source-line-no">245</span><span id="line-245">    util.startMiniCluster(1);</span>
<span class="source-line-no">246</span><span id="line-246">  }</span>
<span class="source-line-no">247</span><span id="line-247"></span>
<span class="source-line-no">248</span><span id="line-248">  @AfterClass</span>
<span class="source-line-no">249</span><span id="line-249">  public static void teardownCluster() throws Exception {</span>
<span class="source-line-no">250</span><span id="line-250">    util.shutdownMiniCluster();</span>
<span class="source-line-no">251</span><span id="line-251">  }</span>
<span class="source-line-no">252</span><span id="line-252"></span>
<span class="source-line-no">253</span><span id="line-253">  /**</span>
<span class="source-line-no">254</span><span id="line-254">   * Checks that all columns have the expected value and that there is the expected number of rows.</span>
<span class="source-line-no">255</span><span id="line-255">   */</span>
<span class="source-line-no">256</span><span id="line-256">  void assertExpectedTable(TableName table, int count, int value) throws IOException {</span>
<span class="source-line-no">257</span><span id="line-257">    TableDescriptor htd = util.getAdmin().getDescriptor(table);</span>
<span class="source-line-no">258</span><span id="line-258">    assertNotNull(htd);</span>
<span class="source-line-no">259</span><span id="line-259">    try (Table t = util.getConnection().getTable(table);</span>
<span class="source-line-no">260</span><span id="line-260">      ResultScanner sr = t.getScanner(new Scan())) {</span>
<span class="source-line-no">261</span><span id="line-261">      int i = 0;</span>
<span class="source-line-no">262</span><span id="line-262">      for (Result r; (r = sr.next()) != null;) {</span>
<span class="source-line-no">263</span><span id="line-263">        r.getNoVersionMap().values().stream().flatMap(m -&gt; m.values().stream())</span>
<span class="source-line-no">264</span><span id="line-264">          .forEach(v -&gt; assertArrayEquals(value(value), v));</span>
<span class="source-line-no">265</span><span id="line-265">        i++;</span>
<span class="source-line-no">266</span><span id="line-266">      }</span>
<span class="source-line-no">267</span><span id="line-267">      assertEquals(count, i);</span>
<span class="source-line-no">268</span><span id="line-268">    } catch (IOException e) {</span>
<span class="source-line-no">269</span><span id="line-269">      fail("Failed due to exception");</span>
<span class="source-line-no">270</span><span id="line-270">    }</span>
<span class="source-line-no">271</span><span id="line-271">  }</span>
<span class="source-line-no">272</span><span id="line-272"></span>
<span class="source-line-no">273</span><span id="line-273">  /**</span>
<span class="source-line-no">274</span><span id="line-274">   * Test that shows that exception thrown from the RS side will result in an exception on the</span>
<span class="source-line-no">275</span><span id="line-275">   * LIHFile client.</span>
<span class="source-line-no">276</span><span id="line-276">   */</span>
<span class="source-line-no">277</span><span id="line-277">  @Test(expected = IOException.class)</span>
<span class="source-line-no">278</span><span id="line-278">  public void testBulkLoadPhaseFailure() throws Exception {</span>
<span class="source-line-no">279</span><span id="line-279">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">280</span><span id="line-280">    final AtomicInteger attmptedCalls = new AtomicInteger();</span>
<span class="source-line-no">281</span><span id="line-281">    final AtomicInteger failedCalls = new AtomicInteger();</span>
<span class="source-line-no">282</span><span id="line-282">    util.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 2);</span>
<span class="source-line-no">283</span><span id="line-283">    try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {</span>
<span class="source-line-no">284</span><span id="line-284">      setupTable(connection, table, 10);</span>
<span class="source-line-no">285</span><span id="line-285">      LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">286</span><span id="line-286">        @Override</span>
<span class="source-line-no">287</span><span id="line-287">        protected List&lt;LoadQueueItem&gt; tryAtomicRegionLoad(Connection connection,</span>
<span class="source-line-no">288</span><span id="line-288">          TableName tableName, final byte[] first, Collection&lt;LoadQueueItem&gt; lqis, boolean copyFile)</span>
<span class="source-line-no">289</span><span id="line-289">          throws IOException {</span>
<span class="source-line-no">290</span><span id="line-290">          int i = attmptedCalls.incrementAndGet();</span>
<span class="source-line-no">291</span><span id="line-291">          if (i == 1) {</span>
<span class="source-line-no">292</span><span id="line-292">            Connection errConn;</span>
<span class="source-line-no">293</span><span id="line-293">            try {</span>
<span class="source-line-no">294</span><span id="line-294">              errConn = getMockedConnection(util.getConfiguration());</span>
<span class="source-line-no">295</span><span id="line-295">            } catch (Exception e) {</span>
<span class="source-line-no">296</span><span id="line-296">              LOG.error(HBaseMarkers.FATAL, "mocking cruft, should never happen", e);</span>
<span class="source-line-no">297</span><span id="line-297">              throw new RuntimeException("mocking cruft, should never happen");</span>
<span class="source-line-no">298</span><span id="line-298">            }</span>
<span class="source-line-no">299</span><span id="line-299">            failedCalls.incrementAndGet();</span>
<span class="source-line-no">300</span><span id="line-300">            return super.tryAtomicRegionLoad(errConn, tableName, first, lqis, true);</span>
<span class="source-line-no">301</span><span id="line-301">          }</span>
<span class="source-line-no">302</span><span id="line-302"></span>
<span class="source-line-no">303</span><span id="line-303">          return super.tryAtomicRegionLoad(connection, tableName, first, lqis, true);</span>
<span class="source-line-no">304</span><span id="line-304">        }</span>
<span class="source-line-no">305</span><span id="line-305">      };</span>
<span class="source-line-no">306</span><span id="line-306">      try {</span>
<span class="source-line-no">307</span><span id="line-307">        // create HFiles for different column families</span>
<span class="source-line-no">308</span><span id="line-308">        Path dir = buildBulkFiles(table, 1);</span>
<span class="source-line-no">309</span><span id="line-309">        try (Table t = connection.getTable(table);</span>
<span class="source-line-no">310</span><span id="line-310">          RegionLocator locator = connection.getRegionLocator(table);</span>
<span class="source-line-no">311</span><span id="line-311">          Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">312</span><span id="line-312">          lih.doBulkLoad(dir, admin, t, locator);</span>
<span class="source-line-no">313</span><span id="line-313">        }</span>
<span class="source-line-no">314</span><span id="line-314">      } finally {</span>
<span class="source-line-no">315</span><span id="line-315">        util.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,</span>
<span class="source-line-no">316</span><span id="line-316">          HConstants.DEFAULT_HBASE_CLIENT_RETRIES_NUMBER);</span>
<span class="source-line-no">317</span><span id="line-317">      }</span>
<span class="source-line-no">318</span><span id="line-318">      fail("doBulkLoad should have thrown an exception");</span>
<span class="source-line-no">319</span><span id="line-319">    }</span>
<span class="source-line-no">320</span><span id="line-320">  }</span>
<span class="source-line-no">321</span><span id="line-321"></span>
<span class="source-line-no">322</span><span id="line-322">  /**</span>
<span class="source-line-no">323</span><span id="line-323">   * Test that shows that exception thrown from the RS side will result in the expected number of</span>
<span class="source-line-no">324</span><span id="line-324">   * retries set by ${@link HConstants#HBASE_CLIENT_RETRIES_NUMBER} when</span>
<span class="source-line-no">325</span><span id="line-325">   * ${@link LoadIncrementalHFiles#RETRY_ON_IO_EXCEPTION} is set</span>
<span class="source-line-no">326</span><span id="line-326">   */</span>
<span class="source-line-no">327</span><span id="line-327">  @Test</span>
<span class="source-line-no">328</span><span id="line-328">  public void testRetryOnIOException() throws Exception {</span>
<span class="source-line-no">329</span><span id="line-329">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">330</span><span id="line-330">    final AtomicInteger calls = new AtomicInteger(0);</span>
<span class="source-line-no">331</span><span id="line-331">    final Connection conn = ConnectionFactory.createConnection(util.getConfiguration());</span>
<span class="source-line-no">332</span><span id="line-332">    util.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 2);</span>
<span class="source-line-no">333</span><span id="line-333">    util.getConfiguration().setBoolean(LoadIncrementalHFiles.RETRY_ON_IO_EXCEPTION, true);</span>
<span class="source-line-no">334</span><span id="line-334">    final LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">335</span><span id="line-335">      @Override</span>
<span class="source-line-no">336</span><span id="line-336">      protected ClientServiceCallable&lt;byte[]&gt; buildClientServiceCallable(Connection conn,</span>
<span class="source-line-no">337</span><span id="line-337">        TableName tableName, byte[] first, Collection&lt;LoadQueueItem&gt; lqis, boolean copyFile) {</span>
<span class="source-line-no">338</span><span id="line-338">        if (</span>
<span class="source-line-no">339</span><span id="line-339">          calls.get() &lt; util.getConfiguration().getInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER,</span>
<span class="source-line-no">340</span><span id="line-340">            HConstants.DEFAULT_HBASE_CLIENT_RETRIES_NUMBER)</span>
<span class="source-line-no">341</span><span id="line-341">        ) {</span>
<span class="source-line-no">342</span><span id="line-342">          calls.getAndIncrement();</span>
<span class="source-line-no">343</span><span id="line-343">          return new ClientServiceCallable&lt;byte[]&gt;(conn, tableName, first,</span>
<span class="source-line-no">344</span><span id="line-344">            new RpcControllerFactory(util.getConfiguration()).newController(),</span>
<span class="source-line-no">345</span><span id="line-345">            HConstants.PRIORITY_UNSET, Collections.emptyMap()) {</span>
<span class="source-line-no">346</span><span id="line-346">            @Override</span>
<span class="source-line-no">347</span><span id="line-347">            public byte[] rpcCall() throws Exception {</span>
<span class="source-line-no">348</span><span id="line-348">              throw new IOException("Error calling something on RegionServer");</span>
<span class="source-line-no">349</span><span id="line-349">            }</span>
<span class="source-line-no">350</span><span id="line-350">          };</span>
<span class="source-line-no">351</span><span id="line-351">        } else {</span>
<span class="source-line-no">352</span><span id="line-352">          return super.buildClientServiceCallable(conn, tableName, first, lqis, true);</span>
<span class="source-line-no">353</span><span id="line-353">        }</span>
<span class="source-line-no">354</span><span id="line-354">      }</span>
<span class="source-line-no">355</span><span id="line-355">    };</span>
<span class="source-line-no">356</span><span id="line-356">    setupTable(conn, table, 10);</span>
<span class="source-line-no">357</span><span id="line-357">    Path dir = buildBulkFiles(table, 1);</span>
<span class="source-line-no">358</span><span id="line-358">    lih.doBulkLoad(dir, conn.getAdmin(), conn.getTable(table), conn.getRegionLocator(table));</span>
<span class="source-line-no">359</span><span id="line-359">    assertEquals(calls.get(), 2);</span>
<span class="source-line-no">360</span><span id="line-360">    util.getConfiguration().setBoolean(LoadIncrementalHFiles.RETRY_ON_IO_EXCEPTION, false);</span>
<span class="source-line-no">361</span><span id="line-361">  }</span>
<span class="source-line-no">362</span><span id="line-362"></span>
<span class="source-line-no">363</span><span id="line-363">  private ClusterConnection getMockedConnection(final Configuration conf)</span>
<span class="source-line-no">364</span><span id="line-364">    throws IOException, org.apache.hbase.thirdparty.com.google.protobuf.ServiceException {</span>
<span class="source-line-no">365</span><span id="line-365">    ClusterConnection c = Mockito.mock(ClusterConnection.class);</span>
<span class="source-line-no">366</span><span id="line-366">    Mockito.when(c.getConfiguration()).thenReturn(conf);</span>
<span class="source-line-no">367</span><span id="line-367">    Mockito.doNothing().when(c).close();</span>
<span class="source-line-no">368</span><span id="line-368">    // Make it so we return a particular location when asked.</span>
<span class="source-line-no">369</span><span id="line-369">    final HRegionLocation loc = new HRegionLocation(RegionInfoBuilder.FIRST_META_REGIONINFO,</span>
<span class="source-line-no">370</span><span id="line-370">      ServerName.valueOf("example.org", 1234, 0));</span>
<span class="source-line-no">371</span><span id="line-371">    Mockito.when(</span>
<span class="source-line-no">372</span><span id="line-372">      c.getRegionLocation((TableName) Mockito.any(), (byte[]) Mockito.any(), Mockito.anyBoolean()))</span>
<span class="source-line-no">373</span><span id="line-373">      .thenReturn(loc);</span>
<span class="source-line-no">374</span><span id="line-374">    Mockito.when(c.locateRegion((TableName) Mockito.any(), (byte[]) Mockito.any())).thenReturn(loc);</span>
<span class="source-line-no">375</span><span id="line-375">    ClientProtos.ClientService.BlockingInterface hri =</span>
<span class="source-line-no">376</span><span id="line-376">      Mockito.mock(ClientProtos.ClientService.BlockingInterface.class);</span>
<span class="source-line-no">377</span><span id="line-377">    Mockito</span>
<span class="source-line-no">378</span><span id="line-378">      .when(hri.bulkLoadHFile((RpcController) Mockito.any(), (BulkLoadHFileRequest) Mockito.any()))</span>
<span class="source-line-no">379</span><span id="line-379">      .thenThrow(new ServiceException(new IOException("injecting bulk load error")));</span>
<span class="source-line-no">380</span><span id="line-380">    Mockito.when(c.getClient(Mockito.any())).thenReturn(hri);</span>
<span class="source-line-no">381</span><span id="line-381">    return c;</span>
<span class="source-line-no">382</span><span id="line-382">  }</span>
<span class="source-line-no">383</span><span id="line-383"></span>
<span class="source-line-no">384</span><span id="line-384">  /**</span>
<span class="source-line-no">385</span><span id="line-385">   * This test exercises the path where there is a split after initial validation but before the</span>
<span class="source-line-no">386</span><span id="line-386">   * atomic bulk load call. We cannot use presplitting to test this path, so we actually inject a</span>
<span class="source-line-no">387</span><span id="line-387">   * split just before the atomic region load.</span>
<span class="source-line-no">388</span><span id="line-388">   */</span>
<span class="source-line-no">389</span><span id="line-389">  @Test</span>
<span class="source-line-no">390</span><span id="line-390">  public void testSplitWhileBulkLoadPhase() throws Exception {</span>
<span class="source-line-no">391</span><span id="line-391">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">392</span><span id="line-392">    try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {</span>
<span class="source-line-no">393</span><span id="line-393">      setupTable(connection, table, 10);</span>
<span class="source-line-no">394</span><span id="line-394">      populateTable(connection, table, 1);</span>
<span class="source-line-no">395</span><span id="line-395">      assertExpectedTable(table, ROWCOUNT, 1);</span>
<span class="source-line-no">396</span><span id="line-396"></span>
<span class="source-line-no">397</span><span id="line-397">      // Now let's cause trouble. This will occur after checks and cause bulk</span>
<span class="source-line-no">398</span><span id="line-398">      // files to fail when attempt to atomically import. This is recoverable.</span>
<span class="source-line-no">399</span><span id="line-399">      final AtomicInteger attemptedCalls = new AtomicInteger();</span>
<span class="source-line-no">400</span><span id="line-400">      LoadIncrementalHFiles lih2 = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">401</span><span id="line-401">        @Override</span>
<span class="source-line-no">402</span><span id="line-402">        protected void bulkLoadPhase(final Table htable, final Connection conn,</span>
<span class="source-line-no">403</span><span id="line-403">          ExecutorService pool, Deque&lt;LoadQueueItem&gt; queue,</span>
<span class="source-line-no">404</span><span id="line-404">          final Multimap&lt;ByteBuffer, LoadQueueItem&gt; regionGroups, boolean copyFile,</span>
<span class="source-line-no">405</span><span id="line-405">          Map&lt;LoadQueueItem, ByteBuffer&gt; item2RegionMap) throws IOException {</span>
<span class="source-line-no">406</span><span id="line-406">          int i = attemptedCalls.incrementAndGet();</span>
<span class="source-line-no">407</span><span id="line-407">          if (i == 1) {</span>
<span class="source-line-no">408</span><span id="line-408">            // On first attempt force a split.</span>
<span class="source-line-no">409</span><span id="line-409">            forceSplit(table);</span>
<span class="source-line-no">410</span><span id="line-410">          }</span>
<span class="source-line-no">411</span><span id="line-411">          super.bulkLoadPhase(htable, conn, pool, queue, regionGroups, copyFile, item2RegionMap);</span>
<span class="source-line-no">412</span><span id="line-412">        }</span>
<span class="source-line-no">413</span><span id="line-413">      };</span>
<span class="source-line-no">414</span><span id="line-414"></span>
<span class="source-line-no">415</span><span id="line-415">      // create HFiles for different column families</span>
<span class="source-line-no">416</span><span id="line-416">      try (Table t = connection.getTable(table);</span>
<span class="source-line-no">417</span><span id="line-417">        RegionLocator locator = connection.getRegionLocator(table);</span>
<span class="source-line-no">418</span><span id="line-418">        Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">419</span><span id="line-419">        Path bulk = buildBulkFiles(table, 2);</span>
<span class="source-line-no">420</span><span id="line-420">        lih2.doBulkLoad(bulk, admin, t, locator);</span>
<span class="source-line-no">421</span><span id="line-421">      }</span>
<span class="source-line-no">422</span><span id="line-422"></span>
<span class="source-line-no">423</span><span id="line-423">      // check that data was loaded</span>
<span class="source-line-no">424</span><span id="line-424">      // The three expected attempts are 1) failure because need to split, 2)</span>
<span class="source-line-no">425</span><span id="line-425">      // load of split top 3) load of split bottom</span>
<span class="source-line-no">426</span><span id="line-426">      assertEquals(3, attemptedCalls.get());</span>
<span class="source-line-no">427</span><span id="line-427">      assertExpectedTable(table, ROWCOUNT, 2);</span>
<span class="source-line-no">428</span><span id="line-428">    }</span>
<span class="source-line-no">429</span><span id="line-429">  }</span>
<span class="source-line-no">430</span><span id="line-430"></span>
<span class="source-line-no">431</span><span id="line-431">  /**</span>
<span class="source-line-no">432</span><span id="line-432">   * This test splits a table and attempts to bulk load. The bulk import files should be split</span>
<span class="source-line-no">433</span><span id="line-433">   * before atomically importing.</span>
<span class="source-line-no">434</span><span id="line-434">   */</span>
<span class="source-line-no">435</span><span id="line-435">  @Test</span>
<span class="source-line-no">436</span><span id="line-436">  public void testGroupOrSplitPresplit() throws Exception {</span>
<span class="source-line-no">437</span><span id="line-437">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">438</span><span id="line-438">    try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {</span>
<span class="source-line-no">439</span><span id="line-439">      setupTable(connection, table, 10);</span>
<span class="source-line-no">440</span><span id="line-440">      populateTable(connection, table, 1);</span>
<span class="source-line-no">441</span><span id="line-441">      assertExpectedTable(connection, table, ROWCOUNT, 1);</span>
<span class="source-line-no">442</span><span id="line-442">      forceSplit(table);</span>
<span class="source-line-no">443</span><span id="line-443"></span>
<span class="source-line-no">444</span><span id="line-444">      final AtomicInteger countedLqis = new AtomicInteger();</span>
<span class="source-line-no">445</span><span id="line-445">      LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">446</span><span id="line-446">        @Override</span>
<span class="source-line-no">447</span><span id="line-447">        protected Pair&lt;List&lt;LoadQueueItem&gt;, String&gt; groupOrSplit(</span>
<span class="source-line-no">448</span><span id="line-448">          Multimap&lt;ByteBuffer, LoadQueueItem&gt; regionGroups, final LoadQueueItem item,</span>
<span class="source-line-no">449</span><span id="line-449">          final Table htable, final Pair&lt;byte[][], byte[][]&gt; startEndKeys) throws IOException {</span>
<span class="source-line-no">450</span><span id="line-450">          Pair&lt;List&lt;LoadQueueItem&gt;, String&gt; lqis =</span>
<span class="source-line-no">451</span><span id="line-451">            super.groupOrSplit(regionGroups, item, htable, startEndKeys);</span>
<span class="source-line-no">452</span><span id="line-452">          if (lqis != null &amp;&amp; lqis.getFirst() != null) {</span>
<span class="source-line-no">453</span><span id="line-453">            countedLqis.addAndGet(lqis.getFirst().size());</span>
<span class="source-line-no">454</span><span id="line-454">          }</span>
<span class="source-line-no">455</span><span id="line-455">          return lqis;</span>
<span class="source-line-no">456</span><span id="line-456">        }</span>
<span class="source-line-no">457</span><span id="line-457">      };</span>
<span class="source-line-no">458</span><span id="line-458"></span>
<span class="source-line-no">459</span><span id="line-459">      // create HFiles for different column families</span>
<span class="source-line-no">460</span><span id="line-460">      Path bulk = buildBulkFiles(table, 2);</span>
<span class="source-line-no">461</span><span id="line-461">      try (Table t = connection.getTable(table);</span>
<span class="source-line-no">462</span><span id="line-462">        RegionLocator locator = connection.getRegionLocator(table);</span>
<span class="source-line-no">463</span><span id="line-463">        Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">464</span><span id="line-464">        lih.doBulkLoad(bulk, admin, t, locator);</span>
<span class="source-line-no">465</span><span id="line-465">      }</span>
<span class="source-line-no">466</span><span id="line-466">      assertExpectedTable(connection, table, ROWCOUNT, 2);</span>
<span class="source-line-no">467</span><span id="line-467">      assertEquals(20, countedLqis.get());</span>
<span class="source-line-no">468</span><span id="line-468">    }</span>
<span class="source-line-no">469</span><span id="line-469">  }</span>
<span class="source-line-no">470</span><span id="line-470"></span>
<span class="source-line-no">471</span><span id="line-471">  @Test</span>
<span class="source-line-no">472</span><span id="line-472">  public void testCorrectSplitPoint() throws Exception {</span>
<span class="source-line-no">473</span><span id="line-473">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">474</span><span id="line-474">    byte[][] SPLIT_KEYS = new byte[][] { Bytes.toBytes("row_00000010"),</span>
<span class="source-line-no">475</span><span id="line-475">      Bytes.toBytes("row_00000020"), Bytes.toBytes("row_00000030"), Bytes.toBytes("row_00000040"),</span>
<span class="source-line-no">476</span><span id="line-476">      Bytes.toBytes("row_00000050"), Bytes.toBytes("row_00000060"), Bytes.toBytes("row_00000070") };</span>
<span class="source-line-no">477</span><span id="line-477">    setupTableWithSplitkeys(table, NUM_CFS, SPLIT_KEYS);</span>
<span class="source-line-no">478</span><span id="line-478"></span>
<span class="source-line-no">479</span><span id="line-479">    final AtomicInteger bulkloadRpcTimes = new AtomicInteger();</span>
<span class="source-line-no">480</span><span id="line-480">    BulkLoadHFilesTool loader = new BulkLoadHFilesTool(util.getConfiguration()) {</span>
<span class="source-line-no">481</span><span id="line-481"></span>
<span class="source-line-no">482</span><span id="line-482">      @Override</span>
<span class="source-line-no">483</span><span id="line-483">      protected void bulkLoadPhase(Table table, Connection conn, ExecutorService pool,</span>
<span class="source-line-no">484</span><span id="line-484">        Deque&lt;LoadIncrementalHFiles.LoadQueueItem&gt; queue,</span>
<span class="source-line-no">485</span><span id="line-485">        Multimap&lt;ByteBuffer, LoadIncrementalHFiles.LoadQueueItem&gt; regionGroups, boolean copyFile,</span>
<span class="source-line-no">486</span><span id="line-486">        Map&lt;LoadIncrementalHFiles.LoadQueueItem, ByteBuffer&gt; item2RegionMap) throws IOException {</span>
<span class="source-line-no">487</span><span id="line-487">        bulkloadRpcTimes.addAndGet(1);</span>
<span class="source-line-no">488</span><span id="line-488">        super.bulkLoadPhase(table, conn, pool, queue, regionGroups, copyFile, item2RegionMap);</span>
<span class="source-line-no">489</span><span id="line-489">      }</span>
<span class="source-line-no">490</span><span id="line-490">    };</span>
<span class="source-line-no">491</span><span id="line-491"></span>
<span class="source-line-no">492</span><span id="line-492">    Path dir = buildBulkFiles(table, 1);</span>
<span class="source-line-no">493</span><span id="line-493">    loader.bulkLoad(table, dir);</span>
<span class="source-line-no">494</span><span id="line-494">    // before HBASE-25281 we need invoke bulkload rpc 8 times</span>
<span class="source-line-no">495</span><span id="line-495">    assertEquals(4, bulkloadRpcTimes.get());</span>
<span class="source-line-no">496</span><span id="line-496">  }</span>
<span class="source-line-no">497</span><span id="line-497"></span>
<span class="source-line-no">498</span><span id="line-498">  /**</span>
<span class="source-line-no">499</span><span id="line-499">   * This test creates a table with many small regions. The bulk load files would be splitted</span>
<span class="source-line-no">500</span><span id="line-500">   * multiple times before all of them can be loaded successfully.</span>
<span class="source-line-no">501</span><span id="line-501">   */</span>
<span class="source-line-no">502</span><span id="line-502">  @Test</span>
<span class="source-line-no">503</span><span id="line-503">  public void testSplitTmpFileCleanUp() throws Exception {</span>
<span class="source-line-no">504</span><span id="line-504">    final TableName table = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">505</span><span id="line-505">    byte[][] SPLIT_KEYS = new byte[][] { Bytes.toBytes("row_00000010"),</span>
<span class="source-line-no">506</span><span id="line-506">      Bytes.toBytes("row_00000020"), Bytes.toBytes("row_00000030"), Bytes.toBytes("row_00000040"),</span>
<span class="source-line-no">507</span><span id="line-507">      Bytes.toBytes("row_00000050") };</span>
<span class="source-line-no">508</span><span id="line-508">    try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {</span>
<span class="source-line-no">509</span><span id="line-509">      setupTableWithSplitkeys(table, 10, SPLIT_KEYS);</span>
<span class="source-line-no">510</span><span id="line-510"></span>
<span class="source-line-no">511</span><span id="line-511">      LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration());</span>
<span class="source-line-no">512</span><span id="line-512"></span>
<span class="source-line-no">513</span><span id="line-513">      // create HFiles</span>
<span class="source-line-no">514</span><span id="line-514">      Path bulk = buildBulkFiles(table, 2);</span>
<span class="source-line-no">515</span><span id="line-515">      try (Table t = connection.getTable(table);</span>
<span class="source-line-no">516</span><span id="line-516">        RegionLocator locator = connection.getRegionLocator(table);</span>
<span class="source-line-no">517</span><span id="line-517">        Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">518</span><span id="line-518">        lih.doBulkLoad(bulk, admin, t, locator);</span>
<span class="source-line-no">519</span><span id="line-519">      }</span>
<span class="source-line-no">520</span><span id="line-520">      // family path</span>
<span class="source-line-no">521</span><span id="line-521">      Path tmpPath = new Path(bulk, family(0));</span>
<span class="source-line-no">522</span><span id="line-522">      // TMP_DIR under family path</span>
<span class="source-line-no">523</span><span id="line-523">      tmpPath = new Path(tmpPath, LoadIncrementalHFiles.TMP_DIR);</span>
<span class="source-line-no">524</span><span id="line-524">      FileSystem fs = bulk.getFileSystem(util.getConfiguration());</span>
<span class="source-line-no">525</span><span id="line-525">      // HFiles have been splitted, there is TMP_DIR</span>
<span class="source-line-no">526</span><span id="line-526">      assertTrue(fs.exists(tmpPath));</span>
<span class="source-line-no">527</span><span id="line-527">      // TMP_DIR should have been cleaned-up</span>
<span class="source-line-no">528</span><span id="line-528">      assertNull(LoadIncrementalHFiles.TMP_DIR + " should be empty.",</span>
<span class="source-line-no">529</span><span id="line-529">        CommonFSUtils.listStatus(fs, tmpPath));</span>
<span class="source-line-no">530</span><span id="line-530">      assertExpectedTable(connection, table, ROWCOUNT, 2);</span>
<span class="source-line-no">531</span><span id="line-531">    }</span>
<span class="source-line-no">532</span><span id="line-532">  }</span>
<span class="source-line-no">533</span><span id="line-533"></span>
<span class="source-line-no">534</span><span id="line-534">  /**</span>
<span class="source-line-no">535</span><span id="line-535">   * This simulates an remote exception which should cause LIHF to exit with an exception.</span>
<span class="source-line-no">536</span><span id="line-536">   */</span>
<span class="source-line-no">537</span><span id="line-537">  @Test(expected = IOException.class)</span>
<span class="source-line-no">538</span><span id="line-538">  public void testGroupOrSplitFailure() throws Exception {</span>
<span class="source-line-no">539</span><span id="line-539">    final TableName tableName = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">540</span><span id="line-540">    try (Connection connection = ConnectionFactory.createConnection(util.getConfiguration())) {</span>
<span class="source-line-no">541</span><span id="line-541">      setupTable(connection, tableName, 10);</span>
<span class="source-line-no">542</span><span id="line-542"></span>
<span class="source-line-no">543</span><span id="line-543">      LoadIncrementalHFiles lih = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">544</span><span id="line-544">        int i = 0;</span>
<span class="source-line-no">545</span><span id="line-545"></span>
<span class="source-line-no">546</span><span id="line-546">        @Override</span>
<span class="source-line-no">547</span><span id="line-547">        protected Pair&lt;List&lt;LoadQueueItem&gt;, String&gt; groupOrSplit(</span>
<span class="source-line-no">548</span><span id="line-548">          Multimap&lt;ByteBuffer, LoadQueueItem&gt; regionGroups, final LoadQueueItem item,</span>
<span class="source-line-no">549</span><span id="line-549">          final Table table, final Pair&lt;byte[][], byte[][]&gt; startEndKeys) throws IOException {</span>
<span class="source-line-no">550</span><span id="line-550">          i++;</span>
<span class="source-line-no">551</span><span id="line-551"></span>
<span class="source-line-no">552</span><span id="line-552">          if (i == 5) {</span>
<span class="source-line-no">553</span><span id="line-553">            throw new IOException("failure");</span>
<span class="source-line-no">554</span><span id="line-554">          }</span>
<span class="source-line-no">555</span><span id="line-555">          return super.groupOrSplit(regionGroups, item, table, startEndKeys);</span>
<span class="source-line-no">556</span><span id="line-556">        }</span>
<span class="source-line-no">557</span><span id="line-557">      };</span>
<span class="source-line-no">558</span><span id="line-558"></span>
<span class="source-line-no">559</span><span id="line-559">      // create HFiles for different column families</span>
<span class="source-line-no">560</span><span id="line-560">      Path dir = buildBulkFiles(tableName, 1);</span>
<span class="source-line-no">561</span><span id="line-561">      try (Table t = connection.getTable(tableName);</span>
<span class="source-line-no">562</span><span id="line-562">        RegionLocator locator = connection.getRegionLocator(tableName);</span>
<span class="source-line-no">563</span><span id="line-563">        Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">564</span><span id="line-564">        lih.doBulkLoad(dir, admin, t, locator);</span>
<span class="source-line-no">565</span><span id="line-565">      }</span>
<span class="source-line-no">566</span><span id="line-566">    }</span>
<span class="source-line-no">567</span><span id="line-567"></span>
<span class="source-line-no">568</span><span id="line-568">    fail("doBulkLoad should have thrown an exception");</span>
<span class="source-line-no">569</span><span id="line-569">  }</span>
<span class="source-line-no">570</span><span id="line-570"></span>
<span class="source-line-no">571</span><span id="line-571">  @Test</span>
<span class="source-line-no">572</span><span id="line-572">  public void testGroupOrSplitWhenRegionHoleExistsInMeta() throws Exception {</span>
<span class="source-line-no">573</span><span id="line-573">    final TableName tableName = TableName.valueOf(name.getMethodName());</span>
<span class="source-line-no">574</span><span id="line-574">    byte[][] SPLIT_KEYS = new byte[][] { Bytes.toBytes("row_00000100") };</span>
<span class="source-line-no">575</span><span id="line-575">    // Share connection. We were failing to find the table with our new reverse scan because it</span>
<span class="source-line-no">576</span><span id="line-576">    // looks for first region, not any region -- that is how it works now. The below removes first</span>
<span class="source-line-no">577</span><span id="line-577">    // region in test. Was reliant on the Connection caching having first region.</span>
<span class="source-line-no">578</span><span id="line-578">    Connection connection = ConnectionFactory.createConnection(util.getConfiguration());</span>
<span class="source-line-no">579</span><span id="line-579">    Table table = connection.getTable(tableName);</span>
<span class="source-line-no">580</span><span id="line-580"></span>
<span class="source-line-no">581</span><span id="line-581">    setupTableWithSplitkeys(tableName, 10, SPLIT_KEYS);</span>
<span class="source-line-no">582</span><span id="line-582">    Path dir = buildBulkFiles(tableName, 2);</span>
<span class="source-line-no">583</span><span id="line-583"></span>
<span class="source-line-no">584</span><span id="line-584">    final AtomicInteger countedLqis = new AtomicInteger();</span>
<span class="source-line-no">585</span><span id="line-585">    LoadIncrementalHFiles loader = new LoadIncrementalHFiles(util.getConfiguration()) {</span>
<span class="source-line-no">586</span><span id="line-586"></span>
<span class="source-line-no">587</span><span id="line-587">      @Override</span>
<span class="source-line-no">588</span><span id="line-588">      protected Pair&lt;List&lt;LoadQueueItem&gt;, String&gt; groupOrSplit(</span>
<span class="source-line-no">589</span><span id="line-589">        Multimap&lt;ByteBuffer, LoadQueueItem&gt; regionGroups, final LoadQueueItem item,</span>
<span class="source-line-no">590</span><span id="line-590">        final Table htable, final Pair&lt;byte[][], byte[][]&gt; startEndKeys) throws IOException {</span>
<span class="source-line-no">591</span><span id="line-591">        Pair&lt;List&lt;LoadQueueItem&gt;, String&gt; lqis =</span>
<span class="source-line-no">592</span><span id="line-592">          super.groupOrSplit(regionGroups, item, htable, startEndKeys);</span>
<span class="source-line-no">593</span><span id="line-593">        if (lqis != null &amp;&amp; lqis.getFirst() != null) {</span>
<span class="source-line-no">594</span><span id="line-594">          countedLqis.addAndGet(lqis.getFirst().size());</span>
<span class="source-line-no">595</span><span id="line-595">        }</span>
<span class="source-line-no">596</span><span id="line-596">        return lqis;</span>
<span class="source-line-no">597</span><span id="line-597">      }</span>
<span class="source-line-no">598</span><span id="line-598">    };</span>
<span class="source-line-no">599</span><span id="line-599"></span>
<span class="source-line-no">600</span><span id="line-600">    // do bulkload when there is no region hole in hbase:meta.</span>
<span class="source-line-no">601</span><span id="line-601">    try (Table t = connection.getTable(tableName);</span>
<span class="source-line-no">602</span><span id="line-602">      RegionLocator locator = connection.getRegionLocator(tableName);</span>
<span class="source-line-no">603</span><span id="line-603">      Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">604</span><span id="line-604">      loader.doBulkLoad(dir, admin, t, locator);</span>
<span class="source-line-no">605</span><span id="line-605">    } catch (Exception e) {</span>
<span class="source-line-no">606</span><span id="line-606">      LOG.error("exeception=", e);</span>
<span class="source-line-no">607</span><span id="line-607">    }</span>
<span class="source-line-no">608</span><span id="line-608">    // check if all the data are loaded into the table.</span>
<span class="source-line-no">609</span><span id="line-609">    this.assertExpectedTable(tableName, ROWCOUNT, 2);</span>
<span class="source-line-no">610</span><span id="line-610"></span>
<span class="source-line-no">611</span><span id="line-611">    dir = buildBulkFiles(tableName, 3);</span>
<span class="source-line-no">612</span><span id="line-612"></span>
<span class="source-line-no">613</span><span id="line-613">    // Mess it up by leaving a hole in the hbase:meta</span>
<span class="source-line-no">614</span><span id="line-614">    List&lt;RegionInfo&gt; regionInfos = MetaTableAccessor.getTableRegions(connection, tableName);</span>
<span class="source-line-no">615</span><span id="line-615">    for (RegionInfo regionInfo : regionInfos) {</span>
<span class="source-line-no">616</span><span id="line-616">      if (Bytes.equals(regionInfo.getStartKey(), HConstants.EMPTY_BYTE_ARRAY)) {</span>
<span class="source-line-no">617</span><span id="line-617">        MetaTableAccessor.deleteRegionInfo(connection, regionInfo);</span>
<span class="source-line-no">618</span><span id="line-618">        break;</span>
<span class="source-line-no">619</span><span id="line-619">      }</span>
<span class="source-line-no">620</span><span id="line-620">    }</span>
<span class="source-line-no">621</span><span id="line-621"></span>
<span class="source-line-no">622</span><span id="line-622">    try (Table t = connection.getTable(tableName);</span>
<span class="source-line-no">623</span><span id="line-623">      RegionLocator locator = connection.getRegionLocator(tableName);</span>
<span class="source-line-no">624</span><span id="line-624">      Admin admin = connection.getAdmin()) {</span>
<span class="source-line-no">625</span><span id="line-625">      loader.doBulkLoad(dir, admin, t, locator);</span>
<span class="source-line-no">626</span><span id="line-626">    } catch (Exception e) {</span>
<span class="source-line-no">627</span><span id="line-627">      LOG.error("exception=", e);</span>
<span class="source-line-no">628</span><span id="line-628">      assertTrue("IOException expected", e instanceof IOException);</span>
<span class="source-line-no">629</span><span id="line-629">    }</span>
<span class="source-line-no">630</span><span id="line-630"></span>
<span class="source-line-no">631</span><span id="line-631">    table.close();</span>
<span class="source-line-no">632</span><span id="line-632"></span>
<span class="source-line-no">633</span><span id="line-633">    // Make sure at least the one region that still exists can be found.</span>
<span class="source-line-no">634</span><span id="line-634">    regionInfos = MetaTableAccessor.getTableRegions(connection, tableName);</span>
<span class="source-line-no">635</span><span id="line-635">    assertTrue(regionInfos.size() &gt;= 1);</span>
<span class="source-line-no">636</span><span id="line-636"></span>
<span class="source-line-no">637</span><span id="line-637">    this.assertExpectedTable(connection, tableName, ROWCOUNT, 2);</span>
<span class="source-line-no">638</span><span id="line-638">    connection.close();</span>
<span class="source-line-no">639</span><span id="line-639">  }</span>
<span class="source-line-no">640</span><span id="line-640"></span>
<span class="source-line-no">641</span><span id="line-641">  /**</span>
<span class="source-line-no">642</span><span id="line-642">   * Checks that all columns have the expected value and that there is the expected number of rows.</span>
<span class="source-line-no">643</span><span id="line-643">   */</span>
<span class="source-line-no">644</span><span id="line-644">  void assertExpectedTable(final Connection connection, TableName table, int count, int value)</span>
<span class="source-line-no">645</span><span id="line-645">    throws IOException {</span>
<span class="source-line-no">646</span><span id="line-646">    TableDescriptor htd = util.getAdmin().getDescriptor(table);</span>
<span class="source-line-no">647</span><span id="line-647">    assertNotNull(htd);</span>
<span class="source-line-no">648</span><span id="line-648">    try (Table t = connection.getTable(table); ResultScanner sr = t.getScanner(new Scan())) {</span>
<span class="source-line-no">649</span><span id="line-649">      int i = 0;</span>
<span class="source-line-no">650</span><span id="line-650">      for (Result r; (r = sr.next()) != null;) {</span>
<span class="source-line-no">651</span><span id="line-651">        r.getNoVersionMap().values().stream().flatMap(m -&gt; m.values().stream())</span>
<span class="source-line-no">652</span><span id="line-652">          .forEach(v -&gt; assertArrayEquals(value(value), v));</span>
<span class="source-line-no">653</span><span id="line-653">        i++;</span>
<span class="source-line-no">654</span><span id="line-654">      }</span>
<span class="source-line-no">655</span><span id="line-655">      assertEquals(count, i);</span>
<span class="source-line-no">656</span><span id="line-656">    } catch (IOException e) {</span>
<span class="source-line-no">657</span><span id="line-657">      fail("Failed due to exception");</span>
<span class="source-line-no">658</span><span id="line-658">    }</span>
<span class="source-line-no">659</span><span id="line-659">  }</span>
<span class="source-line-no">660</span><span id="line-660">}</span>




























































</pre>
</div>
</main>
</body>
</html>
