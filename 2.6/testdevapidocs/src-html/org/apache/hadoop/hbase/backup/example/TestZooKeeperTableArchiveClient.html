<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (17) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.apache.hadoop.hbase.backup.example, class: TestZooKeeperTableArchiveClient">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../../stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="source-line-no">003</span><span id="line-3"> * or more contributor license agreements.  See the NOTICE file</span>
<span class="source-line-no">004</span><span id="line-4"> * distributed with this work for additional information</span>
<span class="source-line-no">005</span><span id="line-5"> * regarding copyright ownership.  The ASF licenses this file</span>
<span class="source-line-no">006</span><span id="line-6"> * to you under the Apache License, Version 2.0 (the</span>
<span class="source-line-no">007</span><span id="line-7"> * "License"); you may not use this file except in compliance</span>
<span class="source-line-no">008</span><span id="line-8"> * with the License.  You may obtain a copy of the License at</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">011</span><span id="line-11"> *</span>
<span class="source-line-no">012</span><span id="line-12"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">013</span><span id="line-13"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">014</span><span id="line-14"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="source-line-no">015</span><span id="line-15"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">016</span><span id="line-16"> * limitations under the License.</span>
<span class="source-line-no">017</span><span id="line-17"> */</span>
<span class="source-line-no">018</span><span id="line-18">package org.apache.hadoop.hbase.backup.example;</span>
<span class="source-line-no">019</span><span id="line-19"></span>
<span class="source-line-no">020</span><span id="line-20">import static org.junit.Assert.assertEquals;</span>
<span class="source-line-no">021</span><span id="line-21">import static org.junit.Assert.assertFalse;</span>
<span class="source-line-no">022</span><span id="line-22">import static org.junit.Assert.assertTrue;</span>
<span class="source-line-no">023</span><span id="line-23">import static org.mockito.ArgumentMatchers.anyList;</span>
<span class="source-line-no">024</span><span id="line-24">import static org.mockito.Mockito.doAnswer;</span>
<span class="source-line-no">025</span><span id="line-25">import static org.mockito.Mockito.doReturn;</span>
<span class="source-line-no">026</span><span id="line-26">import static org.mockito.Mockito.mock;</span>
<span class="source-line-no">027</span><span id="line-27">import static org.mockito.Mockito.spy;</span>
<span class="source-line-no">028</span><span id="line-28"></span>
<span class="source-line-no">029</span><span id="line-29">import java.io.IOException;</span>
<span class="source-line-no">030</span><span id="line-30">import java.util.ArrayList;</span>
<span class="source-line-no">031</span><span id="line-31">import java.util.List;</span>
<span class="source-line-no">032</span><span id="line-32">import java.util.concurrent.CountDownLatch;</span>
<span class="source-line-no">033</span><span id="line-33">import org.apache.hadoop.conf.Configuration;</span>
<span class="source-line-no">034</span><span id="line-34">import org.apache.hadoop.fs.FileStatus;</span>
<span class="source-line-no">035</span><span id="line-35">import org.apache.hadoop.fs.FileSystem;</span>
<span class="source-line-no">036</span><span id="line-36">import org.apache.hadoop.fs.Path;</span>
<span class="source-line-no">037</span><span id="line-37">import org.apache.hadoop.hbase.ChoreService;</span>
<span class="source-line-no">038</span><span id="line-38">import org.apache.hadoop.hbase.HBaseClassTestRule;</span>
<span class="source-line-no">039</span><span id="line-39">import org.apache.hadoop.hbase.HBaseTestingUtility;</span>
<span class="source-line-no">040</span><span id="line-40">import org.apache.hadoop.hbase.HConstants;</span>
<span class="source-line-no">041</span><span id="line-41">import org.apache.hadoop.hbase.Stoppable;</span>
<span class="source-line-no">042</span><span id="line-42">import org.apache.hadoop.hbase.client.ClusterConnection;</span>
<span class="source-line-no">043</span><span id="line-43">import org.apache.hadoop.hbase.client.ColumnFamilyDescriptor;</span>
<span class="source-line-no">044</span><span id="line-44">import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;</span>
<span class="source-line-no">045</span><span id="line-45">import org.apache.hadoop.hbase.client.ConnectionFactory;</span>
<span class="source-line-no">046</span><span id="line-46">import org.apache.hadoop.hbase.client.Put;</span>
<span class="source-line-no">047</span><span id="line-47">import org.apache.hadoop.hbase.master.cleaner.BaseHFileCleanerDelegate;</span>
<span class="source-line-no">048</span><span id="line-48">import org.apache.hadoop.hbase.master.cleaner.DirScanPool;</span>
<span class="source-line-no">049</span><span id="line-49">import org.apache.hadoop.hbase.master.cleaner.HFileCleaner;</span>
<span class="source-line-no">050</span><span id="line-50">import org.apache.hadoop.hbase.regionserver.CompactedHFilesDischarger;</span>
<span class="source-line-no">051</span><span id="line-51">import org.apache.hadoop.hbase.regionserver.HRegion;</span>
<span class="source-line-no">052</span><span id="line-52">import org.apache.hadoop.hbase.regionserver.HStore;</span>
<span class="source-line-no">053</span><span id="line-53">import org.apache.hadoop.hbase.regionserver.RegionServerServices;</span>
<span class="source-line-no">054</span><span id="line-54">import org.apache.hadoop.hbase.testclassification.MediumTests;</span>
<span class="source-line-no">055</span><span id="line-55">import org.apache.hadoop.hbase.testclassification.MiscTests;</span>
<span class="source-line-no">056</span><span id="line-56">import org.apache.hadoop.hbase.util.Bytes;</span>
<span class="source-line-no">057</span><span id="line-57">import org.apache.hadoop.hbase.util.CommonFSUtils;</span>
<span class="source-line-no">058</span><span id="line-58">import org.apache.hadoop.hbase.util.HFileArchiveUtil;</span>
<span class="source-line-no">059</span><span id="line-59">import org.apache.hadoop.hbase.util.StoppableImplementation;</span>
<span class="source-line-no">060</span><span id="line-60">import org.apache.hadoop.hbase.zookeeper.ZKUtil;</span>
<span class="source-line-no">061</span><span id="line-61">import org.apache.hadoop.hbase.zookeeper.ZKWatcher;</span>
<span class="source-line-no">062</span><span id="line-62">import org.apache.zookeeper.KeeperException;</span>
<span class="source-line-no">063</span><span id="line-63">import org.junit.After;</span>
<span class="source-line-no">064</span><span id="line-64">import org.junit.AfterClass;</span>
<span class="source-line-no">065</span><span id="line-65">import org.junit.BeforeClass;</span>
<span class="source-line-no">066</span><span id="line-66">import org.junit.ClassRule;</span>
<span class="source-line-no">067</span><span id="line-67">import org.junit.Test;</span>
<span class="source-line-no">068</span><span id="line-68">import org.junit.experimental.categories.Category;</span>
<span class="source-line-no">069</span><span id="line-69">import org.mockito.invocation.InvocationOnMock;</span>
<span class="source-line-no">070</span><span id="line-70">import org.mockito.stubbing.Answer;</span>
<span class="source-line-no">071</span><span id="line-71">import org.slf4j.Logger;</span>
<span class="source-line-no">072</span><span id="line-72">import org.slf4j.LoggerFactory;</span>
<span class="source-line-no">073</span><span id="line-73"></span>
<span class="source-line-no">074</span><span id="line-74">/**</span>
<span class="source-line-no">075</span><span id="line-75"> * Spin up a small cluster and check that the hfiles of region are properly long-term archived as</span>
<span class="source-line-no">076</span><span id="line-76"> * specified via the {@link ZKTableArchiveClient}.</span>
<span class="source-line-no">077</span><span id="line-77"> */</span>
<span class="source-line-no">078</span><span id="line-78">@Category({ MiscTests.class, MediumTests.class })</span>
<span class="source-line-no">079</span><span id="line-79">public class TestZooKeeperTableArchiveClient {</span>
<span class="source-line-no">080</span><span id="line-80"></span>
<span class="source-line-no">081</span><span id="line-81">  @ClassRule</span>
<span class="source-line-no">082</span><span id="line-82">  public static final HBaseClassTestRule CLASS_RULE =</span>
<span class="source-line-no">083</span><span id="line-83">    HBaseClassTestRule.forClass(TestZooKeeperTableArchiveClient.class);</span>
<span class="source-line-no">084</span><span id="line-84"></span>
<span class="source-line-no">085</span><span id="line-85">  private static final Logger LOG = LoggerFactory.getLogger(TestZooKeeperTableArchiveClient.class);</span>
<span class="source-line-no">086</span><span id="line-86">  private static final HBaseTestingUtility UTIL = HBaseTestingUtility.createLocalHTU();</span>
<span class="source-line-no">087</span><span id="line-87">  private static final String STRING_TABLE_NAME = "test";</span>
<span class="source-line-no">088</span><span id="line-88">  private static final byte[] TEST_FAM = Bytes.toBytes("fam");</span>
<span class="source-line-no">089</span><span id="line-89">  private static final byte[] TABLE_NAME = Bytes.toBytes(STRING_TABLE_NAME);</span>
<span class="source-line-no">090</span><span id="line-90">  private static ZKTableArchiveClient archivingClient;</span>
<span class="source-line-no">091</span><span id="line-91">  private final List&lt;Path&gt; toCleanup = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">092</span><span id="line-92">  private static ClusterConnection CONNECTION;</span>
<span class="source-line-no">093</span><span id="line-93">  private static RegionServerServices rss;</span>
<span class="source-line-no">094</span><span id="line-94">  private static DirScanPool POOL;</span>
<span class="source-line-no">095</span><span id="line-95"></span>
<span class="source-line-no">096</span><span id="line-96">  /**</span>
<span class="source-line-no">097</span><span id="line-97">   * Setup the config for the cluster</span>
<span class="source-line-no">098</span><span id="line-98">   */</span>
<span class="source-line-no">099</span><span id="line-99">  @BeforeClass</span>
<span class="source-line-no">100</span><span id="line-100">  public static void setupCluster() throws Exception {</span>
<span class="source-line-no">101</span><span id="line-101">    setupConf(UTIL.getConfiguration());</span>
<span class="source-line-no">102</span><span id="line-102">    UTIL.startMiniZKCluster();</span>
<span class="source-line-no">103</span><span id="line-103">    CONNECTION = (ClusterConnection) ConnectionFactory.createConnection(UTIL.getConfiguration());</span>
<span class="source-line-no">104</span><span id="line-104">    archivingClient = new ZKTableArchiveClient(UTIL.getConfiguration(), CONNECTION);</span>
<span class="source-line-no">105</span><span id="line-105">    // make hfile archiving node so we can archive files</span>
<span class="source-line-no">106</span><span id="line-106">    ZKWatcher watcher = UTIL.getZooKeeperWatcher();</span>
<span class="source-line-no">107</span><span id="line-107">    String archivingZNode = ZKTableArchiveClient.getArchiveZNode(UTIL.getConfiguration(), watcher);</span>
<span class="source-line-no">108</span><span id="line-108">    ZKUtil.createWithParents(watcher, archivingZNode);</span>
<span class="source-line-no">109</span><span id="line-109">    rss = mock(RegionServerServices.class);</span>
<span class="source-line-no">110</span><span id="line-110">    POOL = DirScanPool.getHFileCleanerScanPool(UTIL.getConfiguration());</span>
<span class="source-line-no">111</span><span id="line-111">  }</span>
<span class="source-line-no">112</span><span id="line-112"></span>
<span class="source-line-no">113</span><span id="line-113">  private static void setupConf(Configuration conf) {</span>
<span class="source-line-no">114</span><span id="line-114">    // only compact with 3 files</span>
<span class="source-line-no">115</span><span id="line-115">    conf.setInt("hbase.hstore.compaction.min", 3);</span>
<span class="source-line-no">116</span><span id="line-116">  }</span>
<span class="source-line-no">117</span><span id="line-117"></span>
<span class="source-line-no">118</span><span id="line-118">  @After</span>
<span class="source-line-no">119</span><span id="line-119">  public void tearDown() throws Exception {</span>
<span class="source-line-no">120</span><span id="line-120">    try {</span>
<span class="source-line-no">121</span><span id="line-121">      FileSystem fs = UTIL.getTestFileSystem();</span>
<span class="source-line-no">122</span><span id="line-122">      // cleanup each of the files/directories registered</span>
<span class="source-line-no">123</span><span id="line-123">      for (Path file : toCleanup) {</span>
<span class="source-line-no">124</span><span id="line-124">        // remove the table and archive directories</span>
<span class="source-line-no">125</span><span id="line-125">        CommonFSUtils.delete(fs, file, true);</span>
<span class="source-line-no">126</span><span id="line-126">      }</span>
<span class="source-line-no">127</span><span id="line-127">    } catch (IOException e) {</span>
<span class="source-line-no">128</span><span id="line-128">      LOG.warn("Failure to delete archive directory", e);</span>
<span class="source-line-no">129</span><span id="line-129">    } finally {</span>
<span class="source-line-no">130</span><span id="line-130">      toCleanup.clear();</span>
<span class="source-line-no">131</span><span id="line-131">    }</span>
<span class="source-line-no">132</span><span id="line-132">    // make sure that backups are off for all tables</span>
<span class="source-line-no">133</span><span id="line-133">    archivingClient.disableHFileBackup();</span>
<span class="source-line-no">134</span><span id="line-134">  }</span>
<span class="source-line-no">135</span><span id="line-135"></span>
<span class="source-line-no">136</span><span id="line-136">  @AfterClass</span>
<span class="source-line-no">137</span><span id="line-137">  public static void cleanupTest() throws Exception {</span>
<span class="source-line-no">138</span><span id="line-138">    if (CONNECTION != null) {</span>
<span class="source-line-no">139</span><span id="line-139">      CONNECTION.close();</span>
<span class="source-line-no">140</span><span id="line-140">    }</span>
<span class="source-line-no">141</span><span id="line-141">    UTIL.shutdownMiniZKCluster();</span>
<span class="source-line-no">142</span><span id="line-142">    if (POOL != null) {</span>
<span class="source-line-no">143</span><span id="line-143">      POOL.shutdownNow();</span>
<span class="source-line-no">144</span><span id="line-144">    }</span>
<span class="source-line-no">145</span><span id="line-145">  }</span>
<span class="source-line-no">146</span><span id="line-146"></span>
<span class="source-line-no">147</span><span id="line-147">  /**</span>
<span class="source-line-no">148</span><span id="line-148">   * Test turning on/off archiving</span>
<span class="source-line-no">149</span><span id="line-149">   */</span>
<span class="source-line-no">150</span><span id="line-150">  @Test</span>
<span class="source-line-no">151</span><span id="line-151">  public void testArchivingEnableDisable() throws Exception {</span>
<span class="source-line-no">152</span><span id="line-152">    // 1. turn on hfile backups</span>
<span class="source-line-no">153</span><span id="line-153">    LOG.debug("----Starting archiving");</span>
<span class="source-line-no">154</span><span id="line-154">    archivingClient.enableHFileBackupAsync(TABLE_NAME);</span>
<span class="source-line-no">155</span><span id="line-155">    assertTrue("Archving didn't get turned on", archivingClient.getArchivingEnabled(TABLE_NAME));</span>
<span class="source-line-no">156</span><span id="line-156"></span>
<span class="source-line-no">157</span><span id="line-157">    // 2. Turn off archiving and make sure its off</span>
<span class="source-line-no">158</span><span id="line-158">    archivingClient.disableHFileBackup();</span>
<span class="source-line-no">159</span><span id="line-159">    assertFalse("Archving didn't get turned off.", archivingClient.getArchivingEnabled(TABLE_NAME));</span>
<span class="source-line-no">160</span><span id="line-160"></span>
<span class="source-line-no">161</span><span id="line-161">    // 3. Check enable/disable on a single table</span>
<span class="source-line-no">162</span><span id="line-162">    archivingClient.enableHFileBackupAsync(TABLE_NAME);</span>
<span class="source-line-no">163</span><span id="line-163">    assertTrue("Archving didn't get turned on", archivingClient.getArchivingEnabled(TABLE_NAME));</span>
<span class="source-line-no">164</span><span id="line-164"></span>
<span class="source-line-no">165</span><span id="line-165">    // 4. Turn off archiving and make sure its off</span>
<span class="source-line-no">166</span><span id="line-166">    archivingClient.disableHFileBackup(TABLE_NAME);</span>
<span class="source-line-no">167</span><span id="line-167">    assertFalse("Archving didn't get turned off for " + STRING_TABLE_NAME,</span>
<span class="source-line-no">168</span><span id="line-168">      archivingClient.getArchivingEnabled(TABLE_NAME));</span>
<span class="source-line-no">169</span><span id="line-169">  }</span>
<span class="source-line-no">170</span><span id="line-170"></span>
<span class="source-line-no">171</span><span id="line-171">  @Test</span>
<span class="source-line-no">172</span><span id="line-172">  public void testArchivingOnSingleTable() throws Exception {</span>
<span class="source-line-no">173</span><span id="line-173">    createArchiveDirectory();</span>
<span class="source-line-no">174</span><span id="line-174">    FileSystem fs = UTIL.getTestFileSystem();</span>
<span class="source-line-no">175</span><span id="line-175">    Path archiveDir = getArchiveDir();</span>
<span class="source-line-no">176</span><span id="line-176">    Path tableDir = getTableDir(STRING_TABLE_NAME);</span>
<span class="source-line-no">177</span><span id="line-177">    toCleanup.add(archiveDir);</span>
<span class="source-line-no">178</span><span id="line-178">    toCleanup.add(tableDir);</span>
<span class="source-line-no">179</span><span id="line-179"></span>
<span class="source-line-no">180</span><span id="line-180">    Configuration conf = UTIL.getConfiguration();</span>
<span class="source-line-no">181</span><span id="line-181">    // setup the delegate</span>
<span class="source-line-no">182</span><span id="line-182">    Stoppable stop = new StoppableImplementation();</span>
<span class="source-line-no">183</span><span id="line-183">    HFileCleaner cleaner = setupAndCreateCleaner(conf, fs, archiveDir, stop);</span>
<span class="source-line-no">184</span><span id="line-184">    List&lt;BaseHFileCleanerDelegate&gt; cleaners = turnOnArchiving(STRING_TABLE_NAME, cleaner);</span>
<span class="source-line-no">185</span><span id="line-185">    final LongTermArchivingHFileCleaner delegate = (LongTermArchivingHFileCleaner) cleaners.get(0);</span>
<span class="source-line-no">186</span><span id="line-186"></span>
<span class="source-line-no">187</span><span id="line-187">    // create the region</span>
<span class="source-line-no">188</span><span id="line-188">    ColumnFamilyDescriptor hcd = ColumnFamilyDescriptorBuilder.of(TEST_FAM);</span>
<span class="source-line-no">189</span><span id="line-189">    HRegion region = UTIL.createTestRegion(STRING_TABLE_NAME, hcd);</span>
<span class="source-line-no">190</span><span id="line-190">    List&lt;HRegion&gt; regions = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">191</span><span id="line-191">    regions.add(region);</span>
<span class="source-line-no">192</span><span id="line-192">    doReturn(regions).when(rss).getRegions();</span>
<span class="source-line-no">193</span><span id="line-193">    final CompactedHFilesDischarger compactionCleaner =</span>
<span class="source-line-no">194</span><span id="line-194">      new CompactedHFilesDischarger(100, stop, rss, false);</span>
<span class="source-line-no">195</span><span id="line-195">    loadFlushAndCompact(region, TEST_FAM);</span>
<span class="source-line-no">196</span><span id="line-196">    compactionCleaner.chore();</span>
<span class="source-line-no">197</span><span id="line-197">    // get the current hfiles in the archive directory</span>
<span class="source-line-no">198</span><span id="line-198">    List&lt;Path&gt; files = getAllFiles(fs, archiveDir);</span>
<span class="source-line-no">199</span><span id="line-199">    if (files == null) {</span>
<span class="source-line-no">200</span><span id="line-200">      CommonFSUtils.logFileSystemState(fs, UTIL.getDataTestDir(), LOG);</span>
<span class="source-line-no">201</span><span id="line-201">      throw new RuntimeException("Didn't archive any files!");</span>
<span class="source-line-no">202</span><span id="line-202">    }</span>
<span class="source-line-no">203</span><span id="line-203">    CountDownLatch finished = setupCleanerWatching(delegate, cleaners, files.size());</span>
<span class="source-line-no">204</span><span id="line-204"></span>
<span class="source-line-no">205</span><span id="line-205">    runCleaner(cleaner, finished, stop);</span>
<span class="source-line-no">206</span><span id="line-206"></span>
<span class="source-line-no">207</span><span id="line-207">    // know the cleaner ran, so now check all the files again to make sure they are still there</span>
<span class="source-line-no">208</span><span id="line-208">    List&lt;Path&gt; archivedFiles = getAllFiles(fs, archiveDir);</span>
<span class="source-line-no">209</span><span id="line-209">    assertEquals("Archived files changed after running archive cleaner.", files, archivedFiles);</span>
<span class="source-line-no">210</span><span id="line-210"></span>
<span class="source-line-no">211</span><span id="line-211">    // but we still have the archive directory</span>
<span class="source-line-no">212</span><span id="line-212">    assertTrue(fs.exists(HFileArchiveUtil.getArchivePath(UTIL.getConfiguration())));</span>
<span class="source-line-no">213</span><span id="line-213">  }</span>
<span class="source-line-no">214</span><span id="line-214"></span>
<span class="source-line-no">215</span><span id="line-215">  /**</span>
<span class="source-line-no">216</span><span id="line-216">   * Test archiving/cleaning across multiple tables, where some are retained, and others aren't</span>
<span class="source-line-no">217</span><span id="line-217">   * @throws Exception on failure</span>
<span class="source-line-no">218</span><span id="line-218">   */</span>
<span class="source-line-no">219</span><span id="line-219">  @Test</span>
<span class="source-line-no">220</span><span id="line-220">  public void testMultipleTables() throws Exception {</span>
<span class="source-line-no">221</span><span id="line-221">    createArchiveDirectory();</span>
<span class="source-line-no">222</span><span id="line-222">    String otherTable = "otherTable";</span>
<span class="source-line-no">223</span><span id="line-223"></span>
<span class="source-line-no">224</span><span id="line-224">    FileSystem fs = UTIL.getTestFileSystem();</span>
<span class="source-line-no">225</span><span id="line-225">    Path archiveDir = getArchiveDir();</span>
<span class="source-line-no">226</span><span id="line-226">    Path tableDir = getTableDir(STRING_TABLE_NAME);</span>
<span class="source-line-no">227</span><span id="line-227">    Path otherTableDir = getTableDir(otherTable);</span>
<span class="source-line-no">228</span><span id="line-228"></span>
<span class="source-line-no">229</span><span id="line-229">    // register cleanup for the created directories</span>
<span class="source-line-no">230</span><span id="line-230">    toCleanup.add(archiveDir);</span>
<span class="source-line-no">231</span><span id="line-231">    toCleanup.add(tableDir);</span>
<span class="source-line-no">232</span><span id="line-232">    toCleanup.add(otherTableDir);</span>
<span class="source-line-no">233</span><span id="line-233">    Configuration conf = UTIL.getConfiguration();</span>
<span class="source-line-no">234</span><span id="line-234">    // setup the delegate</span>
<span class="source-line-no">235</span><span id="line-235">    Stoppable stop = new StoppableImplementation();</span>
<span class="source-line-no">236</span><span id="line-236">    final ChoreService choreService = new ChoreService("TEST_SERVER_NAME");</span>
<span class="source-line-no">237</span><span id="line-237">    HFileCleaner cleaner = setupAndCreateCleaner(conf, fs, archiveDir, stop);</span>
<span class="source-line-no">238</span><span id="line-238">    List&lt;BaseHFileCleanerDelegate&gt; cleaners = turnOnArchiving(STRING_TABLE_NAME, cleaner);</span>
<span class="source-line-no">239</span><span id="line-239">    final LongTermArchivingHFileCleaner delegate = (LongTermArchivingHFileCleaner) cleaners.get(0);</span>
<span class="source-line-no">240</span><span id="line-240">    // create the region</span>
<span class="source-line-no">241</span><span id="line-241">    ColumnFamilyDescriptor hcd = ColumnFamilyDescriptorBuilder.of(TEST_FAM);</span>
<span class="source-line-no">242</span><span id="line-242">    HRegion region = UTIL.createTestRegion(STRING_TABLE_NAME, hcd);</span>
<span class="source-line-no">243</span><span id="line-243">    List&lt;HRegion&gt; regions = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">244</span><span id="line-244">    regions.add(region);</span>
<span class="source-line-no">245</span><span id="line-245">    doReturn(regions).when(rss).getRegions();</span>
<span class="source-line-no">246</span><span id="line-246">    final CompactedHFilesDischarger compactionCleaner =</span>
<span class="source-line-no">247</span><span id="line-247">      new CompactedHFilesDischarger(100, stop, rss, false);</span>
<span class="source-line-no">248</span><span id="line-248">    loadFlushAndCompact(region, TEST_FAM);</span>
<span class="source-line-no">249</span><span id="line-249">    compactionCleaner.chore();</span>
<span class="source-line-no">250</span><span id="line-250">    // create the another table that we don't archive</span>
<span class="source-line-no">251</span><span id="line-251">    hcd = ColumnFamilyDescriptorBuilder.of(TEST_FAM);</span>
<span class="source-line-no">252</span><span id="line-252">    HRegion otherRegion = UTIL.createTestRegion(otherTable, hcd);</span>
<span class="source-line-no">253</span><span id="line-253">    regions = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">254</span><span id="line-254">    regions.add(otherRegion);</span>
<span class="source-line-no">255</span><span id="line-255">    doReturn(regions).when(rss).getRegions();</span>
<span class="source-line-no">256</span><span id="line-256">    final CompactedHFilesDischarger compactionCleaner1 =</span>
<span class="source-line-no">257</span><span id="line-257">      new CompactedHFilesDischarger(100, stop, rss, false);</span>
<span class="source-line-no">258</span><span id="line-258">    loadFlushAndCompact(otherRegion, TEST_FAM);</span>
<span class="source-line-no">259</span><span id="line-259">    compactionCleaner1.chore();</span>
<span class="source-line-no">260</span><span id="line-260">    // get the current hfiles in the archive directory</span>
<span class="source-line-no">261</span><span id="line-261">    // Should be archived</span>
<span class="source-line-no">262</span><span id="line-262">    List&lt;Path&gt; files = getAllFiles(fs, archiveDir);</span>
<span class="source-line-no">263</span><span id="line-263">    if (files == null) {</span>
<span class="source-line-no">264</span><span id="line-264">      CommonFSUtils.logFileSystemState(fs, archiveDir, LOG);</span>
<span class="source-line-no">265</span><span id="line-265">      throw new RuntimeException("Didn't load archive any files!");</span>
<span class="source-line-no">266</span><span id="line-266">    }</span>
<span class="source-line-no">267</span><span id="line-267"></span>
<span class="source-line-no">268</span><span id="line-268">    // make sure we have files from both tables</span>
<span class="source-line-no">269</span><span id="line-269">    int initialCountForPrimary = 0;</span>
<span class="source-line-no">270</span><span id="line-270">    int initialCountForOtherTable = 0;</span>
<span class="source-line-no">271</span><span id="line-271">    for (Path file : files) {</span>
<span class="source-line-no">272</span><span id="line-272">      String tableName = file.getParent().getParent().getParent().getName();</span>
<span class="source-line-no">273</span><span id="line-273">      // check to which table this file belongs</span>
<span class="source-line-no">274</span><span id="line-274">      if (tableName.equals(otherTable)) {</span>
<span class="source-line-no">275</span><span id="line-275">        initialCountForOtherTable++;</span>
<span class="source-line-no">276</span><span id="line-276">      } else if (tableName.equals(STRING_TABLE_NAME)) {</span>
<span class="source-line-no">277</span><span id="line-277">        initialCountForPrimary++;</span>
<span class="source-line-no">278</span><span id="line-278">      }</span>
<span class="source-line-no">279</span><span id="line-279">    }</span>
<span class="source-line-no">280</span><span id="line-280"></span>
<span class="source-line-no">281</span><span id="line-281">    assertTrue("Didn't archive files for:" + STRING_TABLE_NAME, initialCountForPrimary &gt; 0);</span>
<span class="source-line-no">282</span><span id="line-282">    assertTrue("Didn't archive files for:" + otherTable, initialCountForOtherTable &gt; 0);</span>
<span class="source-line-no">283</span><span id="line-283"></span>
<span class="source-line-no">284</span><span id="line-284">    // run the cleaners, checking for each of the directories + files (both should be deleted and</span>
<span class="source-line-no">285</span><span id="line-285">    // need to be checked) in 'otherTable' and the files (which should be retained) in the 'table'</span>
<span class="source-line-no">286</span><span id="line-286">    CountDownLatch finished = setupCleanerWatching(delegate, cleaners, files.size() + 3);</span>
<span class="source-line-no">287</span><span id="line-287">    // run the cleaner</span>
<span class="source-line-no">288</span><span id="line-288">    choreService.scheduleChore(cleaner);</span>
<span class="source-line-no">289</span><span id="line-289">    // wait for the cleaner to check all the files</span>
<span class="source-line-no">290</span><span id="line-290">    finished.await();</span>
<span class="source-line-no">291</span><span id="line-291">    // stop the cleaner</span>
<span class="source-line-no">292</span><span id="line-292">    stop.stop("");</span>
<span class="source-line-no">293</span><span id="line-293"></span>
<span class="source-line-no">294</span><span id="line-294">    // know the cleaner ran, so now check all the files again to make sure they are still there</span>
<span class="source-line-no">295</span><span id="line-295">    List&lt;Path&gt; archivedFiles = getAllFiles(fs, archiveDir);</span>
<span class="source-line-no">296</span><span id="line-296">    int archivedForPrimary = 0;</span>
<span class="source-line-no">297</span><span id="line-297">    for (Path file : archivedFiles) {</span>
<span class="source-line-no">298</span><span id="line-298">      String tableName = file.getParent().getParent().getParent().getName();</span>
<span class="source-line-no">299</span><span id="line-299">      // ensure we don't have files from the non-archived table</span>
<span class="source-line-no">300</span><span id="line-300">      assertFalse("Have a file from the non-archived table: " + file, tableName.equals(otherTable));</span>
<span class="source-line-no">301</span><span id="line-301">      if (tableName.equals(STRING_TABLE_NAME)) {</span>
<span class="source-line-no">302</span><span id="line-302">        archivedForPrimary++;</span>
<span class="source-line-no">303</span><span id="line-303">      }</span>
<span class="source-line-no">304</span><span id="line-304">    }</span>
<span class="source-line-no">305</span><span id="line-305"></span>
<span class="source-line-no">306</span><span id="line-306">    assertEquals("Not all archived files for the primary table were retained.",</span>
<span class="source-line-no">307</span><span id="line-307">      initialCountForPrimary, archivedForPrimary);</span>
<span class="source-line-no">308</span><span id="line-308"></span>
<span class="source-line-no">309</span><span id="line-309">    // but we still have the archive directory</span>
<span class="source-line-no">310</span><span id="line-310">    assertTrue("Archive directory was deleted via archiver", fs.exists(archiveDir));</span>
<span class="source-line-no">311</span><span id="line-311">  }</span>
<span class="source-line-no">312</span><span id="line-312"></span>
<span class="source-line-no">313</span><span id="line-313">  private void createArchiveDirectory() throws IOException {</span>
<span class="source-line-no">314</span><span id="line-314">    // create the archive and test directory</span>
<span class="source-line-no">315</span><span id="line-315">    FileSystem fs = UTIL.getTestFileSystem();</span>
<span class="source-line-no">316</span><span id="line-316">    Path archiveDir = getArchiveDir();</span>
<span class="source-line-no">317</span><span id="line-317">    fs.mkdirs(archiveDir);</span>
<span class="source-line-no">318</span><span id="line-318">  }</span>
<span class="source-line-no">319</span><span id="line-319"></span>
<span class="source-line-no">320</span><span id="line-320">  private Path getArchiveDir() throws IOException {</span>
<span class="source-line-no">321</span><span id="line-321">    return new Path(UTIL.getDataTestDir(), HConstants.HFILE_ARCHIVE_DIRECTORY);</span>
<span class="source-line-no">322</span><span id="line-322">  }</span>
<span class="source-line-no">323</span><span id="line-323"></span>
<span class="source-line-no">324</span><span id="line-324">  private Path getTableDir(String tableName) throws IOException {</span>
<span class="source-line-no">325</span><span id="line-325">    Path testDataDir = UTIL.getDataTestDir();</span>
<span class="source-line-no">326</span><span id="line-326">    CommonFSUtils.setRootDir(UTIL.getConfiguration(), testDataDir);</span>
<span class="source-line-no">327</span><span id="line-327">    return new Path(testDataDir, tableName);</span>
<span class="source-line-no">328</span><span id="line-328">  }</span>
<span class="source-line-no">329</span><span id="line-329"></span>
<span class="source-line-no">330</span><span id="line-330">  private HFileCleaner setupAndCreateCleaner(Configuration conf, FileSystem fs, Path archiveDir,</span>
<span class="source-line-no">331</span><span id="line-331">    Stoppable stop) {</span>
<span class="source-line-no">332</span><span id="line-332">    conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS,</span>
<span class="source-line-no">333</span><span id="line-333">      LongTermArchivingHFileCleaner.class.getCanonicalName());</span>
<span class="source-line-no">334</span><span id="line-334">    return new HFileCleaner(1000, stop, conf, fs, archiveDir, POOL);</span>
<span class="source-line-no">335</span><span id="line-335">  }</span>
<span class="source-line-no">336</span><span id="line-336"></span>
<span class="source-line-no">337</span><span id="line-337">  /**</span>
<span class="source-line-no">338</span><span id="line-338">   * Start archiving table for given hfile cleaner</span>
<span class="source-line-no">339</span><span id="line-339">   * @param tableName table to archive</span>
<span class="source-line-no">340</span><span id="line-340">   * @param cleaner   cleaner to check to make sure change propagated</span>
<span class="source-line-no">341</span><span id="line-341">   * @return underlying {@link LongTermArchivingHFileCleaner} that is managing archiving</span>
<span class="source-line-no">342</span><span id="line-342">   * @throws IOException     on failure</span>
<span class="source-line-no">343</span><span id="line-343">   * @throws KeeperException on failure</span>
<span class="source-line-no">344</span><span id="line-344">   */</span>
<span class="source-line-no">345</span><span id="line-345">  @SuppressWarnings("checkstyle:EmptyBlock")</span>
<span class="source-line-no">346</span><span id="line-346">  private List&lt;BaseHFileCleanerDelegate&gt; turnOnArchiving(String tableName, HFileCleaner cleaner)</span>
<span class="source-line-no">347</span><span id="line-347">    throws IOException, KeeperException {</span>
<span class="source-line-no">348</span><span id="line-348">    // turn on hfile retention</span>
<span class="source-line-no">349</span><span id="line-349">    LOG.debug("----Starting archiving for table:" + tableName);</span>
<span class="source-line-no">350</span><span id="line-350">    archivingClient.enableHFileBackupAsync(Bytes.toBytes(tableName));</span>
<span class="source-line-no">351</span><span id="line-351">    assertTrue("Archving didn't get turned on", archivingClient.getArchivingEnabled(tableName));</span>
<span class="source-line-no">352</span><span id="line-352"></span>
<span class="source-line-no">353</span><span id="line-353">    // wait for the archiver to get the notification</span>
<span class="source-line-no">354</span><span id="line-354">    List&lt;BaseHFileCleanerDelegate&gt; cleaners = cleaner.getDelegatesForTesting();</span>
<span class="source-line-no">355</span><span id="line-355">    LongTermArchivingHFileCleaner delegate = (LongTermArchivingHFileCleaner) cleaners.get(0);</span>
<span class="source-line-no">356</span><span id="line-356">    while (!delegate.archiveTracker.keepHFiles(STRING_TABLE_NAME)) {</span>
<span class="source-line-no">357</span><span id="line-357">      // spin until propagation - should be fast</span>
<span class="source-line-no">358</span><span id="line-358">    }</span>
<span class="source-line-no">359</span><span id="line-359">    return cleaners;</span>
<span class="source-line-no">360</span><span id="line-360">  }</span>
<span class="source-line-no">361</span><span id="line-361"></span>
<span class="source-line-no">362</span><span id="line-362">  /**</span>
<span class="source-line-no">363</span><span id="line-363">   * Spy on the {@link LongTermArchivingHFileCleaner} to ensure we can catch when the cleaner has</span>
<span class="source-line-no">364</span><span id="line-364">   * seen all the files</span>
<span class="source-line-no">365</span><span id="line-365">   * @return a {@link CountDownLatch} to wait on that releases when the cleaner has been called at</span>
<span class="source-line-no">366</span><span id="line-366">   *         least the expected number of times.</span>
<span class="source-line-no">367</span><span id="line-367">   */</span>
<span class="source-line-no">368</span><span id="line-368">  private CountDownLatch setupCleanerWatching(LongTermArchivingHFileCleaner cleaner,</span>
<span class="source-line-no">369</span><span id="line-369">    List&lt;BaseHFileCleanerDelegate&gt; cleaners, final int expected) {</span>
<span class="source-line-no">370</span><span id="line-370">    // replace the cleaner with one that we can can check</span>
<span class="source-line-no">371</span><span id="line-371">    BaseHFileCleanerDelegate delegateSpy = spy(cleaner);</span>
<span class="source-line-no">372</span><span id="line-372">    final int[] counter = new int[] { 0 };</span>
<span class="source-line-no">373</span><span id="line-373">    final CountDownLatch finished = new CountDownLatch(1);</span>
<span class="source-line-no">374</span><span id="line-374">    doAnswer(new Answer&lt;Iterable&lt;FileStatus&gt;&gt;() {</span>
<span class="source-line-no">375</span><span id="line-375"></span>
<span class="source-line-no">376</span><span id="line-376">      @Override</span>
<span class="source-line-no">377</span><span id="line-377">      public Iterable&lt;FileStatus&gt; answer(InvocationOnMock invocation) throws Throwable {</span>
<span class="source-line-no">378</span><span id="line-378">        counter[0]++;</span>
<span class="source-line-no">379</span><span id="line-379">        LOG.debug(counter[0] + "/ " + expected + ") Wrapping call to getDeletableFiles for files: "</span>
<span class="source-line-no">380</span><span id="line-380">          + invocation.getArgument(0));</span>
<span class="source-line-no">381</span><span id="line-381"></span>
<span class="source-line-no">382</span><span id="line-382">        @SuppressWarnings("unchecked")</span>
<span class="source-line-no">383</span><span id="line-383">        Iterable&lt;FileStatus&gt; ret = (Iterable&lt;FileStatus&gt;) invocation.callRealMethod();</span>
<span class="source-line-no">384</span><span id="line-384">        if (counter[0] &gt;= expected) {</span>
<span class="source-line-no">385</span><span id="line-385">          finished.countDown();</span>
<span class="source-line-no">386</span><span id="line-386">        }</span>
<span class="source-line-no">387</span><span id="line-387"></span>
<span class="source-line-no">388</span><span id="line-388">        return ret;</span>
<span class="source-line-no">389</span><span id="line-389">      }</span>
<span class="source-line-no">390</span><span id="line-390">    }).when(delegateSpy).getDeletableFiles(anyList());</span>
<span class="source-line-no">391</span><span id="line-391">    cleaners.set(0, delegateSpy);</span>
<span class="source-line-no">392</span><span id="line-392"></span>
<span class="source-line-no">393</span><span id="line-393">    return finished;</span>
<span class="source-line-no">394</span><span id="line-394">  }</span>
<span class="source-line-no">395</span><span id="line-395"></span>
<span class="source-line-no">396</span><span id="line-396">  /**</span>
<span class="source-line-no">397</span><span id="line-397">   * Get all the files (non-directory entries) in the file system under the passed directory</span>
<span class="source-line-no">398</span><span id="line-398">   * @param dir directory to investigate</span>
<span class="source-line-no">399</span><span id="line-399">   * @return all files under the directory</span>
<span class="source-line-no">400</span><span id="line-400">   */</span>
<span class="source-line-no">401</span><span id="line-401">  private List&lt;Path&gt; getAllFiles(FileSystem fs, Path dir) throws IOException {</span>
<span class="source-line-no">402</span><span id="line-402">    FileStatus[] files = CommonFSUtils.listStatus(fs, dir, null);</span>
<span class="source-line-no">403</span><span id="line-403">    if (files == null) {</span>
<span class="source-line-no">404</span><span id="line-404">      LOG.warn("No files under:" + dir);</span>
<span class="source-line-no">405</span><span id="line-405">      return null;</span>
<span class="source-line-no">406</span><span id="line-406">    }</span>
<span class="source-line-no">407</span><span id="line-407"></span>
<span class="source-line-no">408</span><span id="line-408">    List&lt;Path&gt; allFiles = new ArrayList&lt;&gt;();</span>
<span class="source-line-no">409</span><span id="line-409">    for (FileStatus file : files) {</span>
<span class="source-line-no">410</span><span id="line-410">      if (file.isDirectory()) {</span>
<span class="source-line-no">411</span><span id="line-411">        List&lt;Path&gt; subFiles = getAllFiles(fs, file.getPath());</span>
<span class="source-line-no">412</span><span id="line-412"></span>
<span class="source-line-no">413</span><span id="line-413">        if (subFiles != null) {</span>
<span class="source-line-no">414</span><span id="line-414">          allFiles.addAll(subFiles);</span>
<span class="source-line-no">415</span><span id="line-415">        }</span>
<span class="source-line-no">416</span><span id="line-416"></span>
<span class="source-line-no">417</span><span id="line-417">        continue;</span>
<span class="source-line-no">418</span><span id="line-418">      }</span>
<span class="source-line-no">419</span><span id="line-419">      allFiles.add(file.getPath());</span>
<span class="source-line-no">420</span><span id="line-420">    }</span>
<span class="source-line-no">421</span><span id="line-421">    return allFiles;</span>
<span class="source-line-no">422</span><span id="line-422">  }</span>
<span class="source-line-no">423</span><span id="line-423"></span>
<span class="source-line-no">424</span><span id="line-424">  private void loadFlushAndCompact(HRegion region, byte[] family) throws IOException {</span>
<span class="source-line-no">425</span><span id="line-425">    // create two hfiles in the region</span>
<span class="source-line-no">426</span><span id="line-426">    createHFileInRegion(region, family);</span>
<span class="source-line-no">427</span><span id="line-427">    createHFileInRegion(region, family);</span>
<span class="source-line-no">428</span><span id="line-428"></span>
<span class="source-line-no">429</span><span id="line-429">    HStore s = region.getStore(family);</span>
<span class="source-line-no">430</span><span id="line-430">    int count = s.getStorefilesCount();</span>
<span class="source-line-no">431</span><span id="line-431">    assertTrue("Don't have the expected store files, wanted &gt;= 2 store files, but was:" + count,</span>
<span class="source-line-no">432</span><span id="line-432">      count &gt;= 2);</span>
<span class="source-line-no">433</span><span id="line-433"></span>
<span class="source-line-no">434</span><span id="line-434">    // compact the two files into one file to get files in the archive</span>
<span class="source-line-no">435</span><span id="line-435">    LOG.debug("Compacting stores");</span>
<span class="source-line-no">436</span><span id="line-436">    region.compact(true);</span>
<span class="source-line-no">437</span><span id="line-437">  }</span>
<span class="source-line-no">438</span><span id="line-438"></span>
<span class="source-line-no">439</span><span id="line-439">  /**</span>
<span class="source-line-no">440</span><span id="line-440">   * Create a new hfile in the passed region</span>
<span class="source-line-no">441</span><span id="line-441">   * @param region       region to operate on</span>
<span class="source-line-no">442</span><span id="line-442">   * @param columnFamily family for which to add data</span>
<span class="source-line-no">443</span><span id="line-443">   * @throws IOException if doing the put or flush fails</span>
<span class="source-line-no">444</span><span id="line-444">   */</span>
<span class="source-line-no">445</span><span id="line-445">  private void createHFileInRegion(HRegion region, byte[] columnFamily) throws IOException {</span>
<span class="source-line-no">446</span><span id="line-446">    // put one row in the region</span>
<span class="source-line-no">447</span><span id="line-447">    Put p = new Put(Bytes.toBytes("row"));</span>
<span class="source-line-no">448</span><span id="line-448">    p.addColumn(columnFamily, Bytes.toBytes("Qual"), Bytes.toBytes("v1"));</span>
<span class="source-line-no">449</span><span id="line-449">    region.put(p);</span>
<span class="source-line-no">450</span><span id="line-450">    // flush the region to make a store file</span>
<span class="source-line-no">451</span><span id="line-451">    region.flush(true);</span>
<span class="source-line-no">452</span><span id="line-452">  }</span>
<span class="source-line-no">453</span><span id="line-453"></span>
<span class="source-line-no">454</span><span id="line-454">  /**</span>
<span class="source-line-no">455</span><span id="line-455">   * @param cleaner the cleaner to use</span>
<span class="source-line-no">456</span><span id="line-456">   */</span>
<span class="source-line-no">457</span><span id="line-457">  private void runCleaner(HFileCleaner cleaner, CountDownLatch finished, Stoppable stop)</span>
<span class="source-line-no">458</span><span id="line-458">    throws InterruptedException {</span>
<span class="source-line-no">459</span><span id="line-459">    final ChoreService choreService = new ChoreService("CLEANER_SERVER_NAME");</span>
<span class="source-line-no">460</span><span id="line-460">    // run the cleaner</span>
<span class="source-line-no">461</span><span id="line-461">    choreService.scheduleChore(cleaner);</span>
<span class="source-line-no">462</span><span id="line-462">    // wait for the cleaner to check all the files</span>
<span class="source-line-no">463</span><span id="line-463">    finished.await();</span>
<span class="source-line-no">464</span><span id="line-464">    // stop the cleaner</span>
<span class="source-line-no">465</span><span id="line-465">    stop.stop("");</span>
<span class="source-line-no">466</span><span id="line-466">  }</span>
<span class="source-line-no">467</span><span id="line-467">}</span>




























































</pre>
</div>
</main>
</body>
</html>
