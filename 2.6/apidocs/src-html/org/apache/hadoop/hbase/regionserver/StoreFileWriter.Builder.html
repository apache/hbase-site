<!DOCTYPE HTML>
<html lang="en">
<head>
<!-- Generated by javadoc (17) -->
<title>Source code</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="source: package: org.apache.hadoop.hbase.regionserver, class: StoreFileWriter, class: Builder">
<meta name="generator" content="javadoc/SourceToHTMLConverter">
<link rel="stylesheet" type="text/css" href="../../../../../../stylesheet.css" title="Style">
</head>
<body class="source-page">
<main role="main">
<div class="source-container">
<pre><span class="source-line-no">001</span><span id="line-1">/*</span>
<span class="source-line-no">002</span><span id="line-2"> * Licensed to the Apache Software Foundation (ASF) under one</span>
<span class="source-line-no">003</span><span id="line-3"> * or more contributor license agreements.  See the NOTICE file</span>
<span class="source-line-no">004</span><span id="line-4"> * distributed with this work for additional information</span>
<span class="source-line-no">005</span><span id="line-5"> * regarding copyright ownership.  The ASF licenses this file</span>
<span class="source-line-no">006</span><span id="line-6"> * to you under the Apache License, Version 2.0 (the</span>
<span class="source-line-no">007</span><span id="line-7"> * "License"); you may not use this file except in compliance</span>
<span class="source-line-no">008</span><span id="line-8"> * with the License.  You may obtain a copy of the License at</span>
<span class="source-line-no">009</span><span id="line-9"> *</span>
<span class="source-line-no">010</span><span id="line-10"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="source-line-no">011</span><span id="line-11"> *</span>
<span class="source-line-no">012</span><span id="line-12"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="source-line-no">013</span><span id="line-13"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="source-line-no">014</span><span id="line-14"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="source-line-no">015</span><span id="line-15"> * See the License for the specific language governing permissions and</span>
<span class="source-line-no">016</span><span id="line-16"> * limitations under the License.</span>
<span class="source-line-no">017</span><span id="line-17"> */</span>
<span class="source-line-no">018</span><span id="line-18">package org.apache.hadoop.hbase.regionserver;</span>
<span class="source-line-no">019</span><span id="line-19"></span>
<span class="source-line-no">020</span><span id="line-20">import static org.apache.hadoop.hbase.regionserver.HStoreFile.BLOOM_FILTER_PARAM_KEY;</span>
<span class="source-line-no">021</span><span id="line-21">import static org.apache.hadoop.hbase.regionserver.HStoreFile.BLOOM_FILTER_TYPE_KEY;</span>
<span class="source-line-no">022</span><span id="line-22">import static org.apache.hadoop.hbase.regionserver.HStoreFile.COMPACTION_EVENT_KEY;</span>
<span class="source-line-no">023</span><span id="line-23">import static org.apache.hadoop.hbase.regionserver.HStoreFile.DELETE_FAMILY_COUNT;</span>
<span class="source-line-no">024</span><span id="line-24">import static org.apache.hadoop.hbase.regionserver.HStoreFile.EARLIEST_PUT_TS;</span>
<span class="source-line-no">025</span><span id="line-25">import static org.apache.hadoop.hbase.regionserver.HStoreFile.MAJOR_COMPACTION_KEY;</span>
<span class="source-line-no">026</span><span id="line-26">import static org.apache.hadoop.hbase.regionserver.HStoreFile.MAX_SEQ_ID_KEY;</span>
<span class="source-line-no">027</span><span id="line-27">import static org.apache.hadoop.hbase.regionserver.HStoreFile.MOB_CELLS_COUNT;</span>
<span class="source-line-no">028</span><span id="line-28">import static org.apache.hadoop.hbase.regionserver.HStoreFile.MOB_FILE_REFS;</span>
<span class="source-line-no">029</span><span id="line-29">import static org.apache.hadoop.hbase.regionserver.HStoreFile.TIMERANGE_KEY;</span>
<span class="source-line-no">030</span><span id="line-30"></span>
<span class="source-line-no">031</span><span id="line-31">import java.io.IOException;</span>
<span class="source-line-no">032</span><span id="line-32">import java.net.InetSocketAddress;</span>
<span class="source-line-no">033</span><span id="line-33">import java.util.Collection;</span>
<span class="source-line-no">034</span><span id="line-34">import java.util.Collections;</span>
<span class="source-line-no">035</span><span id="line-35">import java.util.HashSet;</span>
<span class="source-line-no">036</span><span id="line-36">import java.util.Set;</span>
<span class="source-line-no">037</span><span id="line-37">import java.util.UUID;</span>
<span class="source-line-no">038</span><span id="line-38">import java.util.function.Consumer;</span>
<span class="source-line-no">039</span><span id="line-39">import java.util.function.Supplier;</span>
<span class="source-line-no">040</span><span id="line-40">import java.util.regex.Pattern;</span>
<span class="source-line-no">041</span><span id="line-41">import java.util.stream.Collectors;</span>
<span class="source-line-no">042</span><span id="line-42">import org.apache.hadoop.conf.Configuration;</span>
<span class="source-line-no">043</span><span id="line-43">import org.apache.hadoop.fs.FileSystem;</span>
<span class="source-line-no">044</span><span id="line-44">import org.apache.hadoop.fs.Path;</span>
<span class="source-line-no">045</span><span id="line-45">import org.apache.hadoop.hbase.Cell;</span>
<span class="source-line-no">046</span><span id="line-46">import org.apache.hadoop.hbase.HConstants;</span>
<span class="source-line-no">047</span><span id="line-47">import org.apache.hadoop.hbase.KeyValue;</span>
<span class="source-line-no">048</span><span id="line-48">import org.apache.hadoop.hbase.PrivateCellUtil;</span>
<span class="source-line-no">049</span><span id="line-49">import org.apache.hadoop.hbase.TableName;</span>
<span class="source-line-no">050</span><span id="line-50">import org.apache.hadoop.hbase.client.ColumnFamilyDescriptorBuilder;</span>
<span class="source-line-no">051</span><span id="line-51">import org.apache.hadoop.hbase.io.hfile.CacheConfig;</span>
<span class="source-line-no">052</span><span id="line-52">import org.apache.hadoop.hbase.io.hfile.HFile;</span>
<span class="source-line-no">053</span><span id="line-53">import org.apache.hadoop.hbase.io.hfile.HFileContext;</span>
<span class="source-line-no">054</span><span id="line-54">import org.apache.hadoop.hbase.io.hfile.HFileWriterImpl;</span>
<span class="source-line-no">055</span><span id="line-55">import org.apache.hadoop.hbase.mob.MobUtils;</span>
<span class="source-line-no">056</span><span id="line-56">import org.apache.hadoop.hbase.util.BloomContext;</span>
<span class="source-line-no">057</span><span id="line-57">import org.apache.hadoop.hbase.util.BloomFilterFactory;</span>
<span class="source-line-no">058</span><span id="line-58">import org.apache.hadoop.hbase.util.BloomFilterUtil;</span>
<span class="source-line-no">059</span><span id="line-59">import org.apache.hadoop.hbase.util.BloomFilterWriter;</span>
<span class="source-line-no">060</span><span id="line-60">import org.apache.hadoop.hbase.util.Bytes;</span>
<span class="source-line-no">061</span><span id="line-61">import org.apache.hadoop.hbase.util.CommonFSUtils;</span>
<span class="source-line-no">062</span><span id="line-62">import org.apache.hadoop.hbase.util.RowBloomContext;</span>
<span class="source-line-no">063</span><span id="line-63">import org.apache.hadoop.hbase.util.RowColBloomContext;</span>
<span class="source-line-no">064</span><span id="line-64">import org.apache.hadoop.hbase.util.RowPrefixFixedLengthBloomContext;</span>
<span class="source-line-no">065</span><span id="line-65">import org.apache.yetus.audience.InterfaceAudience;</span>
<span class="source-line-no">066</span><span id="line-66">import org.slf4j.Logger;</span>
<span class="source-line-no">067</span><span id="line-67">import org.slf4j.LoggerFactory;</span>
<span class="source-line-no">068</span><span id="line-68"></span>
<span class="source-line-no">069</span><span id="line-69">import org.apache.hbase.thirdparty.com.google.common.base.Preconditions;</span>
<span class="source-line-no">070</span><span id="line-70">import org.apache.hbase.thirdparty.com.google.common.base.Strings;</span>
<span class="source-line-no">071</span><span id="line-71">import org.apache.hbase.thirdparty.com.google.common.collect.SetMultimap;</span>
<span class="source-line-no">072</span><span id="line-72"></span>
<span class="source-line-no">073</span><span id="line-73">import org.apache.hadoop.hbase.shaded.protobuf.ProtobufUtil;</span>
<span class="source-line-no">074</span><span id="line-74"></span>
<span class="source-line-no">075</span><span id="line-75">/**</span>
<span class="source-line-no">076</span><span id="line-76"> * A StoreFile writer. Use this to read/write HBase Store Files. It is package local because it is</span>
<span class="source-line-no">077</span><span id="line-77"> * an implementation detail of the HBase regionserver.</span>
<span class="source-line-no">078</span><span id="line-78"> */</span>
<span class="source-line-no">079</span><span id="line-79">@InterfaceAudience.Private</span>
<span class="source-line-no">080</span><span id="line-80">public class StoreFileWriter implements CellSink, ShipperListener {</span>
<span class="source-line-no">081</span><span id="line-81">  private static final Logger LOG = LoggerFactory.getLogger(StoreFileWriter.class.getName());</span>
<span class="source-line-no">082</span><span id="line-82">  private static final Pattern dash = Pattern.compile("-");</span>
<span class="source-line-no">083</span><span id="line-83">  private final BloomFilterWriter generalBloomFilterWriter;</span>
<span class="source-line-no">084</span><span id="line-84">  private final BloomFilterWriter deleteFamilyBloomFilterWriter;</span>
<span class="source-line-no">085</span><span id="line-85">  private final BloomType bloomType;</span>
<span class="source-line-no">086</span><span id="line-86">  private byte[] bloomParam = null;</span>
<span class="source-line-no">087</span><span id="line-87">  private long earliestPutTs = HConstants.LATEST_TIMESTAMP;</span>
<span class="source-line-no">088</span><span id="line-88">  private long deleteFamilyCnt = 0;</span>
<span class="source-line-no">089</span><span id="line-89">  private BloomContext bloomContext = null;</span>
<span class="source-line-no">090</span><span id="line-90">  private BloomContext deleteFamilyBloomContext = null;</span>
<span class="source-line-no">091</span><span id="line-91">  private final TimeRangeTracker timeRangeTracker;</span>
<span class="source-line-no">092</span><span id="line-92">  private final Supplier&lt;Collection&lt;HStoreFile&gt;&gt; compactedFilesSupplier;</span>
<span class="source-line-no">093</span><span id="line-93"></span>
<span class="source-line-no">094</span><span id="line-94">  protected HFile.Writer writer;</span>
<span class="source-line-no">095</span><span id="line-95"></span>
<span class="source-line-no">096</span><span id="line-96">  /**</span>
<span class="source-line-no">097</span><span id="line-97">   * Creates an HFile.Writer that also write helpful meta data.</span>
<span class="source-line-no">098</span><span id="line-98">   * @param fs                     file system to write to</span>
<span class="source-line-no">099</span><span id="line-99">   * @param path                   file name to create</span>
<span class="source-line-no">100</span><span id="line-100">   * @param conf                   user configuration</span>
<span class="source-line-no">101</span><span id="line-101">   * @param bloomType              bloom filter setting</span>
<span class="source-line-no">102</span><span id="line-102">   * @param maxKeys                the expected maximum number of keys to be added. Was used for</span>
<span class="source-line-no">103</span><span id="line-103">   *                               Bloom filter size in {@link HFile} format version 1.</span>
<span class="source-line-no">104</span><span id="line-104">   * @param favoredNodes           an array of favored nodes or possibly null</span>
<span class="source-line-no">105</span><span id="line-105">   * @param fileContext            The HFile context</span>
<span class="source-line-no">106</span><span id="line-106">   * @param shouldDropCacheBehind  Drop pages written to page cache after writing the store file.</span>
<span class="source-line-no">107</span><span id="line-107">   * @param compactedFilesSupplier Returns the {@link HStore} compacted files which not archived</span>
<span class="source-line-no">108</span><span id="line-108">   * @throws IOException problem writing to FS</span>
<span class="source-line-no">109</span><span id="line-109">   */</span>
<span class="source-line-no">110</span><span id="line-110">  private StoreFileWriter(FileSystem fs, Path path, final Configuration conf, CacheConfig cacheConf,</span>
<span class="source-line-no">111</span><span id="line-111">    BloomType bloomType, long maxKeys, InetSocketAddress[] favoredNodes, HFileContext fileContext,</span>
<span class="source-line-no">112</span><span id="line-112">    boolean shouldDropCacheBehind, Supplier&lt;Collection&lt;HStoreFile&gt;&gt; compactedFilesSupplier)</span>
<span class="source-line-no">113</span><span id="line-113">    throws IOException {</span>
<span class="source-line-no">114</span><span id="line-114">    this.compactedFilesSupplier = compactedFilesSupplier;</span>
<span class="source-line-no">115</span><span id="line-115">    this.timeRangeTracker = TimeRangeTracker.create(TimeRangeTracker.Type.NON_SYNC);</span>
<span class="source-line-no">116</span><span id="line-116">    // TODO : Change all writers to be specifically created for compaction context</span>
<span class="source-line-no">117</span><span id="line-117">    writer =</span>
<span class="source-line-no">118</span><span id="line-118">      HFile.getWriterFactory(conf, cacheConf).withPath(fs, path).withFavoredNodes(favoredNodes)</span>
<span class="source-line-no">119</span><span id="line-119">        .withFileContext(fileContext).withShouldDropCacheBehind(shouldDropCacheBehind).create();</span>
<span class="source-line-no">120</span><span id="line-120"></span>
<span class="source-line-no">121</span><span id="line-121">    generalBloomFilterWriter = BloomFilterFactory.createGeneralBloomAtWrite(conf, cacheConf,</span>
<span class="source-line-no">122</span><span id="line-122">      bloomType, (int) Math.min(maxKeys, Integer.MAX_VALUE), writer);</span>
<span class="source-line-no">123</span><span id="line-123"></span>
<span class="source-line-no">124</span><span id="line-124">    if (generalBloomFilterWriter != null) {</span>
<span class="source-line-no">125</span><span id="line-125">      this.bloomType = bloomType;</span>
<span class="source-line-no">126</span><span id="line-126">      this.bloomParam = BloomFilterUtil.getBloomFilterParam(bloomType, conf);</span>
<span class="source-line-no">127</span><span id="line-127">      if (LOG.isTraceEnabled()) {</span>
<span class="source-line-no">128</span><span id="line-128">        LOG.trace("Bloom filter type for " + path + ": " + this.bloomType + ", param: "</span>
<span class="source-line-no">129</span><span id="line-129">          + (bloomType == BloomType.ROWPREFIX_FIXED_LENGTH</span>
<span class="source-line-no">130</span><span id="line-130">            ? Bytes.toInt(bloomParam)</span>
<span class="source-line-no">131</span><span id="line-131">            : Bytes.toStringBinary(bloomParam))</span>
<span class="source-line-no">132</span><span id="line-132">          + ", " + generalBloomFilterWriter.getClass().getSimpleName());</span>
<span class="source-line-no">133</span><span id="line-133">      }</span>
<span class="source-line-no">134</span><span id="line-134">      // init bloom context</span>
<span class="source-line-no">135</span><span id="line-135">      switch (bloomType) {</span>
<span class="source-line-no">136</span><span id="line-136">        case ROW:</span>
<span class="source-line-no">137</span><span id="line-137">          bloomContext =</span>
<span class="source-line-no">138</span><span id="line-138">            new RowBloomContext(generalBloomFilterWriter, fileContext.getCellComparator());</span>
<span class="source-line-no">139</span><span id="line-139">          break;</span>
<span class="source-line-no">140</span><span id="line-140">        case ROWCOL:</span>
<span class="source-line-no">141</span><span id="line-141">          bloomContext =</span>
<span class="source-line-no">142</span><span id="line-142">            new RowColBloomContext(generalBloomFilterWriter, fileContext.getCellComparator());</span>
<span class="source-line-no">143</span><span id="line-143">          break;</span>
<span class="source-line-no">144</span><span id="line-144">        case ROWPREFIX_FIXED_LENGTH:</span>
<span class="source-line-no">145</span><span id="line-145">          bloomContext = new RowPrefixFixedLengthBloomContext(generalBloomFilterWriter,</span>
<span class="source-line-no">146</span><span id="line-146">            fileContext.getCellComparator(), Bytes.toInt(bloomParam));</span>
<span class="source-line-no">147</span><span id="line-147">          break;</span>
<span class="source-line-no">148</span><span id="line-148">        default:</span>
<span class="source-line-no">149</span><span id="line-149">          throw new IOException(</span>
<span class="source-line-no">150</span><span id="line-150">            "Invalid Bloom filter type: " + bloomType + " (ROW or ROWCOL or ROWPREFIX expected)");</span>
<span class="source-line-no">151</span><span id="line-151">      }</span>
<span class="source-line-no">152</span><span id="line-152">    } else {</span>
<span class="source-line-no">153</span><span id="line-153">      // Not using Bloom filters.</span>
<span class="source-line-no">154</span><span id="line-154">      this.bloomType = BloomType.NONE;</span>
<span class="source-line-no">155</span><span id="line-155">    }</span>
<span class="source-line-no">156</span><span id="line-156"></span>
<span class="source-line-no">157</span><span id="line-157">    // initialize delete family Bloom filter when there is NO RowCol Bloom filter</span>
<span class="source-line-no">158</span><span id="line-158">    if (this.bloomType != BloomType.ROWCOL) {</span>
<span class="source-line-no">159</span><span id="line-159">      this.deleteFamilyBloomFilterWriter = BloomFilterFactory.createDeleteBloomAtWrite(conf,</span>
<span class="source-line-no">160</span><span id="line-160">        cacheConf, (int) Math.min(maxKeys, Integer.MAX_VALUE), writer);</span>
<span class="source-line-no">161</span><span id="line-161">      deleteFamilyBloomContext =</span>
<span class="source-line-no">162</span><span id="line-162">        new RowBloomContext(deleteFamilyBloomFilterWriter, fileContext.getCellComparator());</span>
<span class="source-line-no">163</span><span id="line-163">    } else {</span>
<span class="source-line-no">164</span><span id="line-164">      deleteFamilyBloomFilterWriter = null;</span>
<span class="source-line-no">165</span><span id="line-165">    }</span>
<span class="source-line-no">166</span><span id="line-166">    if (deleteFamilyBloomFilterWriter != null &amp;&amp; LOG.isTraceEnabled()) {</span>
<span class="source-line-no">167</span><span id="line-167">      LOG.trace("Delete Family Bloom filter type for " + path + ": "</span>
<span class="source-line-no">168</span><span id="line-168">        + deleteFamilyBloomFilterWriter.getClass().getSimpleName());</span>
<span class="source-line-no">169</span><span id="line-169">    }</span>
<span class="source-line-no">170</span><span id="line-170">  }</span>
<span class="source-line-no">171</span><span id="line-171"></span>
<span class="source-line-no">172</span><span id="line-172">  public long getPos() throws IOException {</span>
<span class="source-line-no">173</span><span id="line-173">    return ((HFileWriterImpl) writer).getPos();</span>
<span class="source-line-no">174</span><span id="line-174">  }</span>
<span class="source-line-no">175</span><span id="line-175"></span>
<span class="source-line-no">176</span><span id="line-176">  /**</span>
<span class="source-line-no">177</span><span id="line-177">   * Writes meta data. Call before {@link #close()} since its written as meta data to this file.</span>
<span class="source-line-no">178</span><span id="line-178">   * @param maxSequenceId   Maximum sequence id.</span>
<span class="source-line-no">179</span><span id="line-179">   * @param majorCompaction True if this file is product of a major compaction</span>
<span class="source-line-no">180</span><span id="line-180">   * @throws IOException problem writing to FS</span>
<span class="source-line-no">181</span><span id="line-181">   */</span>
<span class="source-line-no">182</span><span id="line-182">  public void appendMetadata(final long maxSequenceId, final boolean majorCompaction)</span>
<span class="source-line-no">183</span><span id="line-183">    throws IOException {</span>
<span class="source-line-no">184</span><span id="line-184">    appendMetadata(maxSequenceId, majorCompaction, Collections.emptySet());</span>
<span class="source-line-no">185</span><span id="line-185">  }</span>
<span class="source-line-no">186</span><span id="line-186"></span>
<span class="source-line-no">187</span><span id="line-187">  /**</span>
<span class="source-line-no">188</span><span id="line-188">   * Writes meta data. Call before {@link #close()} since its written as meta data to this file.</span>
<span class="source-line-no">189</span><span id="line-189">   * @param maxSequenceId   Maximum sequence id.</span>
<span class="source-line-no">190</span><span id="line-190">   * @param majorCompaction True if this file is product of a major compaction</span>
<span class="source-line-no">191</span><span id="line-191">   * @param storeFiles      The compacted store files to generate this new file</span>
<span class="source-line-no">192</span><span id="line-192">   * @throws IOException problem writing to FS</span>
<span class="source-line-no">193</span><span id="line-193">   */</span>
<span class="source-line-no">194</span><span id="line-194">  public void appendMetadata(final long maxSequenceId, final boolean majorCompaction,</span>
<span class="source-line-no">195</span><span id="line-195">    final Collection&lt;HStoreFile&gt; storeFiles) throws IOException {</span>
<span class="source-line-no">196</span><span id="line-196">    writer.appendFileInfo(MAX_SEQ_ID_KEY, Bytes.toBytes(maxSequenceId));</span>
<span class="source-line-no">197</span><span id="line-197">    writer.appendFileInfo(MAJOR_COMPACTION_KEY, Bytes.toBytes(majorCompaction));</span>
<span class="source-line-no">198</span><span id="line-198">    writer.appendFileInfo(COMPACTION_EVENT_KEY, toCompactionEventTrackerBytes(storeFiles));</span>
<span class="source-line-no">199</span><span id="line-199">    appendTrackedTimestampsToMetadata();</span>
<span class="source-line-no">200</span><span id="line-200">  }</span>
<span class="source-line-no">201</span><span id="line-201"></span>
<span class="source-line-no">202</span><span id="line-202">  /**</span>
<span class="source-line-no">203</span><span id="line-203">   * Used when write {@link HStoreFile#COMPACTION_EVENT_KEY} to new file's file info. The compacted</span>
<span class="source-line-no">204</span><span id="line-204">   * store files's name is needed. But if the compacted store file is a result of compaction, it's</span>
<span class="source-line-no">205</span><span id="line-205">   * compacted files which still not archived is needed, too. And don't need to add compacted files</span>
<span class="source-line-no">206</span><span id="line-206">   * recursively. If file A, B, C compacted to new file D, and file D compacted to new file E, will</span>
<span class="source-line-no">207</span><span id="line-207">   * write A, B, C, D to file E's compacted files. So if file E compacted to new file F, will add E</span>
<span class="source-line-no">208</span><span id="line-208">   * to F's compacted files first, then add E's compacted files: A, B, C, D to it. And no need to</span>
<span class="source-line-no">209</span><span id="line-209">   * add D's compacted file, as D's compacted files has been in E's compacted files, too. See</span>
<span class="source-line-no">210</span><span id="line-210">   * HBASE-20724 for more details.</span>
<span class="source-line-no">211</span><span id="line-211">   * @param storeFiles The compacted store files to generate this new file</span>
<span class="source-line-no">212</span><span id="line-212">   * @return bytes of CompactionEventTracker</span>
<span class="source-line-no">213</span><span id="line-213">   */</span>
<span class="source-line-no">214</span><span id="line-214">  private byte[] toCompactionEventTrackerBytes(Collection&lt;HStoreFile&gt; storeFiles) {</span>
<span class="source-line-no">215</span><span id="line-215">    Set&lt;String&gt; notArchivedCompactedStoreFiles = this.compactedFilesSupplier.get().stream()</span>
<span class="source-line-no">216</span><span id="line-216">      .map(sf -&gt; sf.getPath().getName()).collect(Collectors.toSet());</span>
<span class="source-line-no">217</span><span id="line-217">    Set&lt;String&gt; compactedStoreFiles = new HashSet&lt;&gt;();</span>
<span class="source-line-no">218</span><span id="line-218">    for (HStoreFile storeFile : storeFiles) {</span>
<span class="source-line-no">219</span><span id="line-219">      compactedStoreFiles.add(storeFile.getFileInfo().getPath().getName());</span>
<span class="source-line-no">220</span><span id="line-220">      for (String csf : storeFile.getCompactedStoreFiles()) {</span>
<span class="source-line-no">221</span><span id="line-221">        if (notArchivedCompactedStoreFiles.contains(csf)) {</span>
<span class="source-line-no">222</span><span id="line-222">          compactedStoreFiles.add(csf);</span>
<span class="source-line-no">223</span><span id="line-223">        }</span>
<span class="source-line-no">224</span><span id="line-224">      }</span>
<span class="source-line-no">225</span><span id="line-225">    }</span>
<span class="source-line-no">226</span><span id="line-226">    return ProtobufUtil.toCompactionEventTrackerBytes(compactedStoreFiles);</span>
<span class="source-line-no">227</span><span id="line-227">  }</span>
<span class="source-line-no">228</span><span id="line-228"></span>
<span class="source-line-no">229</span><span id="line-229">  /**</span>
<span class="source-line-no">230</span><span id="line-230">   * Writes meta data. Call before {@link #close()} since its written as meta data to this file.</span>
<span class="source-line-no">231</span><span id="line-231">   * @param maxSequenceId   Maximum sequence id.</span>
<span class="source-line-no">232</span><span id="line-232">   * @param majorCompaction True if this file is product of a major compaction</span>
<span class="source-line-no">233</span><span id="line-233">   * @param mobCellsCount   The number of mob cells.</span>
<span class="source-line-no">234</span><span id="line-234">   * @throws IOException problem writing to FS</span>
<span class="source-line-no">235</span><span id="line-235">   */</span>
<span class="source-line-no">236</span><span id="line-236">  public void appendMetadata(final long maxSequenceId, final boolean majorCompaction,</span>
<span class="source-line-no">237</span><span id="line-237">    final long mobCellsCount) throws IOException {</span>
<span class="source-line-no">238</span><span id="line-238">    writer.appendFileInfo(MAX_SEQ_ID_KEY, Bytes.toBytes(maxSequenceId));</span>
<span class="source-line-no">239</span><span id="line-239">    writer.appendFileInfo(MAJOR_COMPACTION_KEY, Bytes.toBytes(majorCompaction));</span>
<span class="source-line-no">240</span><span id="line-240">    writer.appendFileInfo(MOB_CELLS_COUNT, Bytes.toBytes(mobCellsCount));</span>
<span class="source-line-no">241</span><span id="line-241">    appendTrackedTimestampsToMetadata();</span>
<span class="source-line-no">242</span><span id="line-242">  }</span>
<span class="source-line-no">243</span><span id="line-243"></span>
<span class="source-line-no">244</span><span id="line-244">  /**</span>
<span class="source-line-no">245</span><span id="line-245">   * Appends MOB - specific metadata (even if it is empty)</span>
<span class="source-line-no">246</span><span id="line-246">   * @param mobRefSet - original table -&gt; set of MOB file names</span>
<span class="source-line-no">247</span><span id="line-247">   * @throws IOException problem writing to FS</span>
<span class="source-line-no">248</span><span id="line-248">   */</span>
<span class="source-line-no">249</span><span id="line-249">  public void appendMobMetadata(SetMultimap&lt;TableName, String&gt; mobRefSet) throws IOException {</span>
<span class="source-line-no">250</span><span id="line-250">    writer.appendFileInfo(MOB_FILE_REFS, MobUtils.serializeMobFileRefs(mobRefSet));</span>
<span class="source-line-no">251</span><span id="line-251">  }</span>
<span class="source-line-no">252</span><span id="line-252"></span>
<span class="source-line-no">253</span><span id="line-253">  /**</span>
<span class="source-line-no">254</span><span id="line-254">   * Add TimestampRange and earliest put timestamp to Metadata</span>
<span class="source-line-no">255</span><span id="line-255">   */</span>
<span class="source-line-no">256</span><span id="line-256">  public void appendTrackedTimestampsToMetadata() throws IOException {</span>
<span class="source-line-no">257</span><span id="line-257">    // TODO: The StoreFileReader always converts the byte[] to TimeRange</span>
<span class="source-line-no">258</span><span id="line-258">    // via TimeRangeTracker, so we should write the serialization data of TimeRange directly.</span>
<span class="source-line-no">259</span><span id="line-259">    appendFileInfo(TIMERANGE_KEY, TimeRangeTracker.toByteArray(timeRangeTracker));</span>
<span class="source-line-no">260</span><span id="line-260">    appendFileInfo(EARLIEST_PUT_TS, Bytes.toBytes(earliestPutTs));</span>
<span class="source-line-no">261</span><span id="line-261">  }</span>
<span class="source-line-no">262</span><span id="line-262"></span>
<span class="source-line-no">263</span><span id="line-263">  /**</span>
<span class="source-line-no">264</span><span id="line-264">   * Record the earlest Put timestamp. If the timeRangeTracker is not set, update TimeRangeTracker</span>
<span class="source-line-no">265</span><span id="line-265">   * to include the timestamp of this key</span>
<span class="source-line-no">266</span><span id="line-266">   */</span>
<span class="source-line-no">267</span><span id="line-267">  public void trackTimestamps(final Cell cell) {</span>
<span class="source-line-no">268</span><span id="line-268">    if (KeyValue.Type.Put.getCode() == cell.getTypeByte()) {</span>
<span class="source-line-no">269</span><span id="line-269">      earliestPutTs = Math.min(earliestPutTs, cell.getTimestamp());</span>
<span class="source-line-no">270</span><span id="line-270">    }</span>
<span class="source-line-no">271</span><span id="line-271">    timeRangeTracker.includeTimestamp(cell);</span>
<span class="source-line-no">272</span><span id="line-272">  }</span>
<span class="source-line-no">273</span><span id="line-273"></span>
<span class="source-line-no">274</span><span id="line-274">  private void appendGeneralBloomfilter(final Cell cell) throws IOException {</span>
<span class="source-line-no">275</span><span id="line-275">    if (this.generalBloomFilterWriter != null) {</span>
<span class="source-line-no">276</span><span id="line-276">      /*</span>
<span class="source-line-no">277</span><span id="line-277">       * http://2.bp.blogspot.com/_Cib_A77V54U/StZMrzaKufI/AAAAAAAAADo/ZhK7bGoJdMQ/s400/KeyValue.png</span>
<span class="source-line-no">278</span><span id="line-278">       * Key = RowLen + Row + FamilyLen + Column [Family + Qualifier] + Timestamp 3 Types of</span>
<span class="source-line-no">279</span><span id="line-279">       * Filtering: 1. Row = Row 2. RowCol = Row + Qualifier 3. RowPrefixFixedLength = Fixed Length</span>
<span class="source-line-no">280</span><span id="line-280">       * Row Prefix</span>
<span class="source-line-no">281</span><span id="line-281">       */</span>
<span class="source-line-no">282</span><span id="line-282">      bloomContext.writeBloom(cell);</span>
<span class="source-line-no">283</span><span id="line-283">    }</span>
<span class="source-line-no">284</span><span id="line-284">  }</span>
<span class="source-line-no">285</span><span id="line-285"></span>
<span class="source-line-no">286</span><span id="line-286">  private void appendDeleteFamilyBloomFilter(final Cell cell) throws IOException {</span>
<span class="source-line-no">287</span><span id="line-287">    if (!PrivateCellUtil.isDeleteFamily(cell) &amp;&amp; !PrivateCellUtil.isDeleteFamilyVersion(cell)) {</span>
<span class="source-line-no">288</span><span id="line-288">      return;</span>
<span class="source-line-no">289</span><span id="line-289">    }</span>
<span class="source-line-no">290</span><span id="line-290"></span>
<span class="source-line-no">291</span><span id="line-291">    // increase the number of delete family in the store file</span>
<span class="source-line-no">292</span><span id="line-292">    deleteFamilyCnt++;</span>
<span class="source-line-no">293</span><span id="line-293">    if (this.deleteFamilyBloomFilterWriter != null) {</span>
<span class="source-line-no">294</span><span id="line-294">      deleteFamilyBloomContext.writeBloom(cell);</span>
<span class="source-line-no">295</span><span id="line-295">    }</span>
<span class="source-line-no">296</span><span id="line-296">  }</span>
<span class="source-line-no">297</span><span id="line-297"></span>
<span class="source-line-no">298</span><span id="line-298">  @Override</span>
<span class="source-line-no">299</span><span id="line-299">  public void append(final Cell cell) throws IOException {</span>
<span class="source-line-no">300</span><span id="line-300">    appendGeneralBloomfilter(cell);</span>
<span class="source-line-no">301</span><span id="line-301">    appendDeleteFamilyBloomFilter(cell);</span>
<span class="source-line-no">302</span><span id="line-302">    writer.append(cell);</span>
<span class="source-line-no">303</span><span id="line-303">    trackTimestamps(cell);</span>
<span class="source-line-no">304</span><span id="line-304">  }</span>
<span class="source-line-no">305</span><span id="line-305"></span>
<span class="source-line-no">306</span><span id="line-306">  @Override</span>
<span class="source-line-no">307</span><span id="line-307">  public void beforeShipped() throws IOException {</span>
<span class="source-line-no">308</span><span id="line-308">    // For now these writer will always be of type ShipperListener true.</span>
<span class="source-line-no">309</span><span id="line-309">    // TODO : Change all writers to be specifically created for compaction context</span>
<span class="source-line-no">310</span><span id="line-310">    writer.beforeShipped();</span>
<span class="source-line-no">311</span><span id="line-311">    if (generalBloomFilterWriter != null) {</span>
<span class="source-line-no">312</span><span id="line-312">      generalBloomFilterWriter.beforeShipped();</span>
<span class="source-line-no">313</span><span id="line-313">    }</span>
<span class="source-line-no">314</span><span id="line-314">    if (deleteFamilyBloomFilterWriter != null) {</span>
<span class="source-line-no">315</span><span id="line-315">      deleteFamilyBloomFilterWriter.beforeShipped();</span>
<span class="source-line-no">316</span><span id="line-316">    }</span>
<span class="source-line-no">317</span><span id="line-317">  }</span>
<span class="source-line-no">318</span><span id="line-318"></span>
<span class="source-line-no">319</span><span id="line-319">  public Path getPath() {</span>
<span class="source-line-no">320</span><span id="line-320">    return this.writer.getPath();</span>
<span class="source-line-no">321</span><span id="line-321">  }</span>
<span class="source-line-no">322</span><span id="line-322"></span>
<span class="source-line-no">323</span><span id="line-323">  public boolean hasGeneralBloom() {</span>
<span class="source-line-no">324</span><span id="line-324">    return this.generalBloomFilterWriter != null;</span>
<span class="source-line-no">325</span><span id="line-325">  }</span>
<span class="source-line-no">326</span><span id="line-326"></span>
<span class="source-line-no">327</span><span id="line-327">  /**</span>
<span class="source-line-no">328</span><span id="line-328">   * For unit testing only.</span>
<span class="source-line-no">329</span><span id="line-329">   * @return the Bloom filter used by this writer.</span>
<span class="source-line-no">330</span><span id="line-330">   */</span>
<span class="source-line-no">331</span><span id="line-331">  BloomFilterWriter getGeneralBloomWriter() {</span>
<span class="source-line-no">332</span><span id="line-332">    return generalBloomFilterWriter;</span>
<span class="source-line-no">333</span><span id="line-333">  }</span>
<span class="source-line-no">334</span><span id="line-334"></span>
<span class="source-line-no">335</span><span id="line-335">  private boolean closeBloomFilter(BloomFilterWriter bfw) throws IOException {</span>
<span class="source-line-no">336</span><span id="line-336">    boolean haveBloom = (bfw != null &amp;&amp; bfw.getKeyCount() &gt; 0);</span>
<span class="source-line-no">337</span><span id="line-337">    if (haveBloom) {</span>
<span class="source-line-no">338</span><span id="line-338">      bfw.compactBloom();</span>
<span class="source-line-no">339</span><span id="line-339">    }</span>
<span class="source-line-no">340</span><span id="line-340">    return haveBloom;</span>
<span class="source-line-no">341</span><span id="line-341">  }</span>
<span class="source-line-no">342</span><span id="line-342"></span>
<span class="source-line-no">343</span><span id="line-343">  private boolean closeGeneralBloomFilter() throws IOException {</span>
<span class="source-line-no">344</span><span id="line-344">    boolean hasGeneralBloom = closeBloomFilter(generalBloomFilterWriter);</span>
<span class="source-line-no">345</span><span id="line-345"></span>
<span class="source-line-no">346</span><span id="line-346">    // add the general Bloom filter writer and append file info</span>
<span class="source-line-no">347</span><span id="line-347">    if (hasGeneralBloom) {</span>
<span class="source-line-no">348</span><span id="line-348">      writer.addGeneralBloomFilter(generalBloomFilterWriter);</span>
<span class="source-line-no">349</span><span id="line-349">      writer.appendFileInfo(BLOOM_FILTER_TYPE_KEY, Bytes.toBytes(bloomType.toString()));</span>
<span class="source-line-no">350</span><span id="line-350">      if (bloomParam != null) {</span>
<span class="source-line-no">351</span><span id="line-351">        writer.appendFileInfo(BLOOM_FILTER_PARAM_KEY, bloomParam);</span>
<span class="source-line-no">352</span><span id="line-352">      }</span>
<span class="source-line-no">353</span><span id="line-353">      bloomContext.addLastBloomKey(writer);</span>
<span class="source-line-no">354</span><span id="line-354">    }</span>
<span class="source-line-no">355</span><span id="line-355">    return hasGeneralBloom;</span>
<span class="source-line-no">356</span><span id="line-356">  }</span>
<span class="source-line-no">357</span><span id="line-357"></span>
<span class="source-line-no">358</span><span id="line-358">  private boolean closeDeleteFamilyBloomFilter() throws IOException {</span>
<span class="source-line-no">359</span><span id="line-359">    boolean hasDeleteFamilyBloom = closeBloomFilter(deleteFamilyBloomFilterWriter);</span>
<span class="source-line-no">360</span><span id="line-360"></span>
<span class="source-line-no">361</span><span id="line-361">    // add the delete family Bloom filter writer</span>
<span class="source-line-no">362</span><span id="line-362">    if (hasDeleteFamilyBloom) {</span>
<span class="source-line-no">363</span><span id="line-363">      writer.addDeleteFamilyBloomFilter(deleteFamilyBloomFilterWriter);</span>
<span class="source-line-no">364</span><span id="line-364">    }</span>
<span class="source-line-no">365</span><span id="line-365"></span>
<span class="source-line-no">366</span><span id="line-366">    // append file info about the number of delete family kvs</span>
<span class="source-line-no">367</span><span id="line-367">    // even if there is no delete family Bloom.</span>
<span class="source-line-no">368</span><span id="line-368">    writer.appendFileInfo(DELETE_FAMILY_COUNT, Bytes.toBytes(this.deleteFamilyCnt));</span>
<span class="source-line-no">369</span><span id="line-369"></span>
<span class="source-line-no">370</span><span id="line-370">    return hasDeleteFamilyBloom;</span>
<span class="source-line-no">371</span><span id="line-371">  }</span>
<span class="source-line-no">372</span><span id="line-372"></span>
<span class="source-line-no">373</span><span id="line-373">  public void close() throws IOException {</span>
<span class="source-line-no">374</span><span id="line-374">    boolean hasGeneralBloom = this.closeGeneralBloomFilter();</span>
<span class="source-line-no">375</span><span id="line-375">    boolean hasDeleteFamilyBloom = this.closeDeleteFamilyBloomFilter();</span>
<span class="source-line-no">376</span><span id="line-376"></span>
<span class="source-line-no">377</span><span id="line-377">    writer.close();</span>
<span class="source-line-no">378</span><span id="line-378"></span>
<span class="source-line-no">379</span><span id="line-379">    // Log final Bloom filter statistics. This needs to be done after close()</span>
<span class="source-line-no">380</span><span id="line-380">    // because compound Bloom filters might be finalized as part of closing.</span>
<span class="source-line-no">381</span><span id="line-381">    if (LOG.isTraceEnabled()) {</span>
<span class="source-line-no">382</span><span id="line-382">      LOG.trace(</span>
<span class="source-line-no">383</span><span id="line-383">        (hasGeneralBloom ? "" : "NO ") + "General Bloom and " + (hasDeleteFamilyBloom ? "" : "NO ")</span>
<span class="source-line-no">384</span><span id="line-384">          + "DeleteFamily" + " was added to HFile " + getPath());</span>
<span class="source-line-no">385</span><span id="line-385">    }</span>
<span class="source-line-no">386</span><span id="line-386"></span>
<span class="source-line-no">387</span><span id="line-387">  }</span>
<span class="source-line-no">388</span><span id="line-388"></span>
<span class="source-line-no">389</span><span id="line-389">  public void appendFileInfo(byte[] key, byte[] value) throws IOException {</span>
<span class="source-line-no">390</span><span id="line-390">    writer.appendFileInfo(key, value);</span>
<span class="source-line-no">391</span><span id="line-391">  }</span>
<span class="source-line-no">392</span><span id="line-392"></span>
<span class="source-line-no">393</span><span id="line-393">  /**</span>
<span class="source-line-no">394</span><span id="line-394">   * For use in testing.</span>
<span class="source-line-no">395</span><span id="line-395">   */</span>
<span class="source-line-no">396</span><span id="line-396">  HFile.Writer getHFileWriter() {</span>
<span class="source-line-no">397</span><span id="line-397">    return writer;</span>
<span class="source-line-no">398</span><span id="line-398">  }</span>
<span class="source-line-no">399</span><span id="line-399"></span>
<span class="source-line-no">400</span><span id="line-400">  /**</span>
<span class="source-line-no">401</span><span id="line-401">   * @param dir Directory to create file in.</span>
<span class="source-line-no">402</span><span id="line-402">   * @return random filename inside passed &lt;code&gt;dir&lt;/code&gt;</span>
<span class="source-line-no">403</span><span id="line-403">   */</span>
<span class="source-line-no">404</span><span id="line-404">  public static Path getUniqueFile(final FileSystem fs, final Path dir) throws IOException {</span>
<span class="source-line-no">405</span><span id="line-405">    if (!fs.getFileStatus(dir).isDirectory()) {</span>
<span class="source-line-no">406</span><span id="line-406">      throw new IOException("Expecting " + dir.toString() + " to be a directory");</span>
<span class="source-line-no">407</span><span id="line-407">    }</span>
<span class="source-line-no">408</span><span id="line-408">    return new Path(dir, dash.matcher(UUID.randomUUID().toString()).replaceAll(""));</span>
<span class="source-line-no">409</span><span id="line-409">  }</span>
<span class="source-line-no">410</span><span id="line-410"></span>
<span class="source-line-no">411</span><span id="line-411">  @edu.umd.cs.findbugs.annotations.SuppressWarnings(value = "ICAST_INTEGER_MULTIPLY_CAST_TO_LONG",</span>
<span class="source-line-no">412</span><span id="line-412">      justification = "Will not overflow")</span>
<span class="source-line-no">413</span><span id="line-413">  public static class Builder {</span>
<span class="source-line-no">414</span><span id="line-414">    private final Configuration conf;</span>
<span class="source-line-no">415</span><span id="line-415">    private final CacheConfig cacheConf;</span>
<span class="source-line-no">416</span><span id="line-416">    private final FileSystem fs;</span>
<span class="source-line-no">417</span><span id="line-417"></span>
<span class="source-line-no">418</span><span id="line-418">    private BloomType bloomType = BloomType.NONE;</span>
<span class="source-line-no">419</span><span id="line-419">    private long maxKeyCount = 0;</span>
<span class="source-line-no">420</span><span id="line-420">    private Path dir;</span>
<span class="source-line-no">421</span><span id="line-421">    private Path filePath;</span>
<span class="source-line-no">422</span><span id="line-422">    private InetSocketAddress[] favoredNodes;</span>
<span class="source-line-no">423</span><span id="line-423">    private HFileContext fileContext;</span>
<span class="source-line-no">424</span><span id="line-424">    private boolean shouldDropCacheBehind;</span>
<span class="source-line-no">425</span><span id="line-425">    private Supplier&lt;Collection&lt;HStoreFile&gt;&gt; compactedFilesSupplier = () -&gt; Collections.emptySet();</span>
<span class="source-line-no">426</span><span id="line-426">    private String fileStoragePolicy;</span>
<span class="source-line-no">427</span><span id="line-427">    // this is used to track the creation of the StoreFileWriter, mainly used for the SFT</span>
<span class="source-line-no">428</span><span id="line-428">    // implementation where we will write store files directly to the final place, instead of</span>
<span class="source-line-no">429</span><span id="line-429">    // writing a tmp file first. Under this scenario, we will have a background task to purge the</span>
<span class="source-line-no">430</span><span id="line-430">    // store files which are not recorded in the SFT, but for the newly created store file writer,</span>
<span class="source-line-no">431</span><span id="line-431">    // they are not tracked in SFT, so here we need to record them and treat them specially.</span>
<span class="source-line-no">432</span><span id="line-432">    private Consumer&lt;Path&gt; writerCreationTracker;</span>
<span class="source-line-no">433</span><span id="line-433"></span>
<span class="source-line-no">434</span><span id="line-434">    public Builder(Configuration conf, CacheConfig cacheConf, FileSystem fs) {</span>
<span class="source-line-no">435</span><span id="line-435">      this.conf = conf;</span>
<span class="source-line-no">436</span><span id="line-436">      this.cacheConf = cacheConf;</span>
<span class="source-line-no">437</span><span id="line-437">      this.fs = fs;</span>
<span class="source-line-no">438</span><span id="line-438">    }</span>
<span class="source-line-no">439</span><span id="line-439"></span>
<span class="source-line-no">440</span><span id="line-440">    /**</span>
<span class="source-line-no">441</span><span id="line-441">     * Creates Builder with cache configuration disabled</span>
<span class="source-line-no">442</span><span id="line-442">     */</span>
<span class="source-line-no">443</span><span id="line-443">    public Builder(Configuration conf, FileSystem fs) {</span>
<span class="source-line-no">444</span><span id="line-444">      this.conf = conf;</span>
<span class="source-line-no">445</span><span id="line-445">      this.cacheConf = CacheConfig.DISABLED;</span>
<span class="source-line-no">446</span><span id="line-446">      this.fs = fs;</span>
<span class="source-line-no">447</span><span id="line-447">    }</span>
<span class="source-line-no">448</span><span id="line-448"></span>
<span class="source-line-no">449</span><span id="line-449">    /**</span>
<span class="source-line-no">450</span><span id="line-450">     * Use either this method or {@link #withFilePath}, but not both.</span>
<span class="source-line-no">451</span><span id="line-451">     * @param dir Path to column family directory. The directory is created if does not exist. The</span>
<span class="source-line-no">452</span><span id="line-452">     *            file is given a unique name within this directory.</span>
<span class="source-line-no">453</span><span id="line-453">     * @return this (for chained invocation)</span>
<span class="source-line-no">454</span><span id="line-454">     */</span>
<span class="source-line-no">455</span><span id="line-455">    public Builder withOutputDir(Path dir) {</span>
<span class="source-line-no">456</span><span id="line-456">      Preconditions.checkNotNull(dir);</span>
<span class="source-line-no">457</span><span id="line-457">      this.dir = dir;</span>
<span class="source-line-no">458</span><span id="line-458">      return this;</span>
<span class="source-line-no">459</span><span id="line-459">    }</span>
<span class="source-line-no">460</span><span id="line-460"></span>
<span class="source-line-no">461</span><span id="line-461">    /**</span>
<span class="source-line-no">462</span><span id="line-462">     * Use either this method or {@link #withOutputDir}, but not both.</span>
<span class="source-line-no">463</span><span id="line-463">     * @param filePath the StoreFile path to write</span>
<span class="source-line-no">464</span><span id="line-464">     * @return this (for chained invocation)</span>
<span class="source-line-no">465</span><span id="line-465">     */</span>
<span class="source-line-no">466</span><span id="line-466">    public Builder withFilePath(Path filePath) {</span>
<span class="source-line-no">467</span><span id="line-467">      Preconditions.checkNotNull(filePath);</span>
<span class="source-line-no">468</span><span id="line-468">      this.filePath = filePath;</span>
<span class="source-line-no">469</span><span id="line-469">      return this;</span>
<span class="source-line-no">470</span><span id="line-470">    }</span>
<span class="source-line-no">471</span><span id="line-471"></span>
<span class="source-line-no">472</span><span id="line-472">    /**</span>
<span class="source-line-no">473</span><span id="line-473">     * @param favoredNodes an array of favored nodes or possibly null</span>
<span class="source-line-no">474</span><span id="line-474">     * @return this (for chained invocation)</span>
<span class="source-line-no">475</span><span id="line-475">     */</span>
<span class="source-line-no">476</span><span id="line-476">    public Builder withFavoredNodes(InetSocketAddress[] favoredNodes) {</span>
<span class="source-line-no">477</span><span id="line-477">      this.favoredNodes = favoredNodes;</span>
<span class="source-line-no">478</span><span id="line-478">      return this;</span>
<span class="source-line-no">479</span><span id="line-479">    }</span>
<span class="source-line-no">480</span><span id="line-480"></span>
<span class="source-line-no">481</span><span id="line-481">    public Builder withBloomType(BloomType bloomType) {</span>
<span class="source-line-no">482</span><span id="line-482">      Preconditions.checkNotNull(bloomType);</span>
<span class="source-line-no">483</span><span id="line-483">      this.bloomType = bloomType;</span>
<span class="source-line-no">484</span><span id="line-484">      return this;</span>
<span class="source-line-no">485</span><span id="line-485">    }</span>
<span class="source-line-no">486</span><span id="line-486"></span>
<span class="source-line-no">487</span><span id="line-487">    /**</span>
<span class="source-line-no">488</span><span id="line-488">     * @param maxKeyCount estimated maximum number of keys we expect to add</span>
<span class="source-line-no">489</span><span id="line-489">     * @return this (for chained invocation)</span>
<span class="source-line-no">490</span><span id="line-490">     */</span>
<span class="source-line-no">491</span><span id="line-491">    public Builder withMaxKeyCount(long maxKeyCount) {</span>
<span class="source-line-no">492</span><span id="line-492">      this.maxKeyCount = maxKeyCount;</span>
<span class="source-line-no">493</span><span id="line-493">      return this;</span>
<span class="source-line-no">494</span><span id="line-494">    }</span>
<span class="source-line-no">495</span><span id="line-495"></span>
<span class="source-line-no">496</span><span id="line-496">    public Builder withFileContext(HFileContext fileContext) {</span>
<span class="source-line-no">497</span><span id="line-497">      this.fileContext = fileContext;</span>
<span class="source-line-no">498</span><span id="line-498">      return this;</span>
<span class="source-line-no">499</span><span id="line-499">    }</span>
<span class="source-line-no">500</span><span id="line-500"></span>
<span class="source-line-no">501</span><span id="line-501">    public Builder withShouldDropCacheBehind(boolean shouldDropCacheBehind) {</span>
<span class="source-line-no">502</span><span id="line-502">      this.shouldDropCacheBehind = shouldDropCacheBehind;</span>
<span class="source-line-no">503</span><span id="line-503">      return this;</span>
<span class="source-line-no">504</span><span id="line-504">    }</span>
<span class="source-line-no">505</span><span id="line-505"></span>
<span class="source-line-no">506</span><span id="line-506">    public Builder</span>
<span class="source-line-no">507</span><span id="line-507">      withCompactedFilesSupplier(Supplier&lt;Collection&lt;HStoreFile&gt;&gt; compactedFilesSupplier) {</span>
<span class="source-line-no">508</span><span id="line-508">      this.compactedFilesSupplier = compactedFilesSupplier;</span>
<span class="source-line-no">509</span><span id="line-509">      return this;</span>
<span class="source-line-no">510</span><span id="line-510">    }</span>
<span class="source-line-no">511</span><span id="line-511"></span>
<span class="source-line-no">512</span><span id="line-512">    public Builder withFileStoragePolicy(String fileStoragePolicy) {</span>
<span class="source-line-no">513</span><span id="line-513">      this.fileStoragePolicy = fileStoragePolicy;</span>
<span class="source-line-no">514</span><span id="line-514">      return this;</span>
<span class="source-line-no">515</span><span id="line-515">    }</span>
<span class="source-line-no">516</span><span id="line-516"></span>
<span class="source-line-no">517</span><span id="line-517">    public Builder withWriterCreationTracker(Consumer&lt;Path&gt; writerCreationTracker) {</span>
<span class="source-line-no">518</span><span id="line-518">      this.writerCreationTracker = writerCreationTracker;</span>
<span class="source-line-no">519</span><span id="line-519">      return this;</span>
<span class="source-line-no">520</span><span id="line-520">    }</span>
<span class="source-line-no">521</span><span id="line-521"></span>
<span class="source-line-no">522</span><span id="line-522">    /**</span>
<span class="source-line-no">523</span><span id="line-523">     * Create a store file writer. Client is responsible for closing file when done. If metadata,</span>
<span class="source-line-no">524</span><span id="line-524">     * add BEFORE closing using {@link StoreFileWriter#appendMetadata}.</span>
<span class="source-line-no">525</span><span id="line-525">     */</span>
<span class="source-line-no">526</span><span id="line-526">    public StoreFileWriter build() throws IOException {</span>
<span class="source-line-no">527</span><span id="line-527">      if ((dir == null ? 0 : 1) + (filePath == null ? 0 : 1) != 1) {</span>
<span class="source-line-no">528</span><span id="line-528">        throw new IllegalArgumentException("Either specify parent directory " + "or file path");</span>
<span class="source-line-no">529</span><span id="line-529">      }</span>
<span class="source-line-no">530</span><span id="line-530"></span>
<span class="source-line-no">531</span><span id="line-531">      if (dir == null) {</span>
<span class="source-line-no">532</span><span id="line-532">        dir = filePath.getParent();</span>
<span class="source-line-no">533</span><span id="line-533">      }</span>
<span class="source-line-no">534</span><span id="line-534"></span>
<span class="source-line-no">535</span><span id="line-535">      if (!fs.exists(dir)) {</span>
<span class="source-line-no">536</span><span id="line-536">        // Handle permission for non-HDFS filesystem properly</span>
<span class="source-line-no">537</span><span id="line-537">        // See HBASE-17710</span>
<span class="source-line-no">538</span><span id="line-538">        HRegionFileSystem.mkdirs(fs, conf, dir);</span>
<span class="source-line-no">539</span><span id="line-539">      }</span>
<span class="source-line-no">540</span><span id="line-540"></span>
<span class="source-line-no">541</span><span id="line-541">      // set block storage policy for temp path</span>
<span class="source-line-no">542</span><span id="line-542">      String policyName = this.conf.get(ColumnFamilyDescriptorBuilder.STORAGE_POLICY);</span>
<span class="source-line-no">543</span><span id="line-543">      if (null == policyName) {</span>
<span class="source-line-no">544</span><span id="line-544">        policyName = this.conf.get(HStore.BLOCK_STORAGE_POLICY_KEY);</span>
<span class="source-line-no">545</span><span id="line-545">      }</span>
<span class="source-line-no">546</span><span id="line-546">      CommonFSUtils.setStoragePolicy(this.fs, dir, policyName);</span>
<span class="source-line-no">547</span><span id="line-547"></span>
<span class="source-line-no">548</span><span id="line-548">      if (filePath == null) {</span>
<span class="source-line-no">549</span><span id="line-549">        // The stored file and related blocks will used the directory based StoragePolicy.</span>
<span class="source-line-no">550</span><span id="line-550">        // Because HDFS DistributedFileSystem does not support create files with storage policy</span>
<span class="source-line-no">551</span><span id="line-551">        // before version 3.3.0 (See HDFS-13209). Use child dir here is to make stored files</span>
<span class="source-line-no">552</span><span id="line-552">        // satisfy the specific storage policy when writing. So as to avoid later data movement.</span>
<span class="source-line-no">553</span><span id="line-553">        // We don't want to change whole temp dir to 'fileStoragePolicy'.</span>
<span class="source-line-no">554</span><span id="line-554">        if (!Strings.isNullOrEmpty(fileStoragePolicy)) {</span>
<span class="source-line-no">555</span><span id="line-555">          dir = new Path(dir, HConstants.STORAGE_POLICY_PREFIX + fileStoragePolicy);</span>
<span class="source-line-no">556</span><span id="line-556">          if (!fs.exists(dir)) {</span>
<span class="source-line-no">557</span><span id="line-557">            HRegionFileSystem.mkdirs(fs, conf, dir);</span>
<span class="source-line-no">558</span><span id="line-558">            LOG.info(</span>
<span class="source-line-no">559</span><span id="line-559">              "Create tmp dir " + dir.toString() + " with storage policy: " + fileStoragePolicy);</span>
<span class="source-line-no">560</span><span id="line-560">          }</span>
<span class="source-line-no">561</span><span id="line-561">          CommonFSUtils.setStoragePolicy(this.fs, dir, fileStoragePolicy);</span>
<span class="source-line-no">562</span><span id="line-562">        }</span>
<span class="source-line-no">563</span><span id="line-563">        filePath = getUniqueFile(fs, dir);</span>
<span class="source-line-no">564</span><span id="line-564">        if (!BloomFilterFactory.isGeneralBloomEnabled(conf)) {</span>
<span class="source-line-no">565</span><span id="line-565">          bloomType = BloomType.NONE;</span>
<span class="source-line-no">566</span><span id="line-566">        }</span>
<span class="source-line-no">567</span><span id="line-567">      }</span>
<span class="source-line-no">568</span><span id="line-568">      // make sure we call this before actually create the writer</span>
<span class="source-line-no">569</span><span id="line-569">      // in fact, it is not a big deal to even add an inexistent file to the track, as we will never</span>
<span class="source-line-no">570</span><span id="line-570">      // try to delete it and finally we will clean the tracker up after compaction. But if the file</span>
<span class="source-line-no">571</span><span id="line-571">      // cleaner find the file but we haven't recorded it yet, it may accidentally delete the file</span>
<span class="source-line-no">572</span><span id="line-572">      // and cause problem.</span>
<span class="source-line-no">573</span><span id="line-573">      if (writerCreationTracker != null) {</span>
<span class="source-line-no">574</span><span id="line-574">        writerCreationTracker.accept(filePath);</span>
<span class="source-line-no">575</span><span id="line-575">      }</span>
<span class="source-line-no">576</span><span id="line-576">      return new StoreFileWriter(fs, filePath, conf, cacheConf, bloomType, maxKeyCount,</span>
<span class="source-line-no">577</span><span id="line-577">        favoredNodes, fileContext, shouldDropCacheBehind, compactedFilesSupplier);</span>
<span class="source-line-no">578</span><span id="line-578">    }</span>
<span class="source-line-no">579</span><span id="line-579">  }</span>
<span class="source-line-no">580</span><span id="line-580">}</span>




























































</pre>
</div>
</main>
</body>
</html>
